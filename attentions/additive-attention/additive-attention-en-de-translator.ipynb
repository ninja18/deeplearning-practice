{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "249bc84683f06fb4",
      "metadata": {
        "id": "249bc84683f06fb4"
      },
      "source": [
        "## Additive attention\n",
        "Paper: [Neural machine translation by jointly learning to align and translate](https://arxiv.org/pdf/1409.0473) - Bahdanau et. al 2015\n",
        "\n",
        "Dataset: [Multi30K English to Deutsche dataset](https://huggingface.co/datasets/bentrevett/multi30k)\n",
        "\n",
        "Model: Use LSTM as encoder and decoder\n",
        "\n",
        "#### Model variations\n",
        "- Stacked LSTM encoder decoder\n",
        "- BiLSTM encoder + LSTM decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xWsacfa4zkuK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWsacfa4zkuK",
        "outputId": "4a7eb2c8-d0ad-4884-8590-5bfdb6d21670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: early-stopping-pytorch in /usr/local/lib/python3.12/dist-packages (1.0.10)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from early-stopping-pytorch) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from early-stopping-pytorch) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->early-stopping-pytorch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->early-stopping-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.0->early-stopping-pytorch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# colab specifics\n",
        "%pip install early-stopping-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "e268df56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e268df56",
        "outputId": "5d0c1584-2d3c-4096-993c-cb1ec340fdae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x117797490>"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 1557\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "5c25a3e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c25a3e2",
        "outputId": "a97b55ff-db28-4167-89f0-538e74981455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29000\n",
            "{'en': 'Two young, White males are outside near many bushes.', 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset(\"bentrevett/multi30k\", split=\"train\")\n",
        "print(len(train_dataset))\n",
        "print(train_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "134b8b8d",
      "metadata": {
        "id": "134b8b8d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "TOKEN_RE = re.compile(r\"\\w+|[^\\w\\s]\")\n",
        "def word_tokenize(text):\n",
        "    text = text.lower().strip()\n",
        "    return TOKEN_RE.findall(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ad0677d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad0677d3",
        "outputId": "cbb04087-4816-4f29-d276-2855e3e8d03e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hello', ',', 'world', '!']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokenize(\"Hello, world!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "c7980113",
      "metadata": {
        "id": "c7980113"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "PAD, BOS, EOS, UNK = \"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"\n",
        "\n",
        "SPECIAL_TOKENS = [PAD, BOS, EOS, UNK]\n",
        "\n",
        "def build_vocab(tokenized_texts, max_vocab_size=10000, min_freq=3):\n",
        "    counter = Counter(token for text in tokenized_texts for token in text)\n",
        "    vocab = SPECIAL_TOKENS.copy()\n",
        "\n",
        "    for token, freq in counter.most_common():\n",
        "        if freq < min_freq:\n",
        "            break\n",
        "        if len(vocab) >= max_vocab_size:\n",
        "            break\n",
        "        if token not in vocab:\n",
        "            vocab.append(token)\n",
        "\n",
        "    vocab_to_index = {token: index for index, token in enumerate(vocab)}\n",
        "    index_to_vocab = {index: token for token, index in vocab_to_index.items()}\n",
        "\n",
        "    return vocab_to_index, index_to_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "56900004",
      "metadata": {
        "id": "56900004"
      },
      "outputs": [],
      "source": [
        "def add_special_tokens(tokens):\n",
        "    return [BOS] + tokens + [EOS]\n",
        "\n",
        "def remove_special_tokens(tokens):\n",
        "    return [token for token in tokens if token not in [PAD, BOS, EOS]]\n",
        "\n",
        "def encode(token_to_index, text):\n",
        "    return [token_to_index.get(token, token_to_index[UNK]) for token in text]\n",
        "\n",
        "def decode(index_to_token, indices):\n",
        "    return \" \".join(remove_special_tokens([index_to_token.get(index, UNK) for index in indices]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "b02a28ac",
      "metadata": {
        "id": "b02a28ac"
      },
      "outputs": [],
      "source": [
        "# Load data and build vocab\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(lambda x: {\"en\": word_tokenize(x[\"en\"]), \"de\": word_tokenize(x[\"de\"])}, batched=False)\n",
        "\n",
        "en_vocab_to_index, en_index_to_vocab = build_vocab(\n",
        "    [item[\"en\"] for item in tokenized_train_dataset]\n",
        ")\n",
        "de_vocab_to_index, de_index_to_vocab = build_vocab(\n",
        "    [item[\"de\"] for item in tokenized_train_dataset]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1b2339a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b2339a5",
        "outputId": "7ae4621f-510b-4588-f4fa-8051d76e70a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Vocab size: 4560\n",
            "German Vocab size: 5422\n",
            "{'en': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.'], 'de': ['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']}\n"
          ]
        }
      ],
      "source": [
        "print(f\"English Vocab size: {len(en_vocab_to_index)}\")\n",
        "print(f\"German Vocab size: {len(de_vocab_to_index)}\")\n",
        "print(tokenized_train_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "3c84c570",
      "metadata": {
        "id": "3c84c570"
      },
      "outputs": [],
      "source": [
        "def preprocess(batch, source_lang, target_lang, source_vocab_to_index, target_vocab_to_index):\n",
        "    source_encodings = [encode(source_vocab_to_index, add_special_tokens(word_tokenize(text))) for text in batch[source_lang]]\n",
        "    target_encodings = [encode(target_vocab_to_index, add_special_tokens(word_tokenize(text))) for text in batch[target_lang]]\n",
        "\n",
        "    return {\"source\": source_encodings, \"target\": target_encodings}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "7f8435e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8435e5",
        "outputId": "cf35c0dd-35b4-4778-c983-b2d98773beeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'source': tensor([   1,   18,   27,  215,   31,   85,   20,   89,    7,   15,  115,    3,\n",
            "        3149,    4,    2]), 'target': tensor([   1,   16,   24,   15,   25,  776,   17,   57,   80,  204, 1305,    5,\n",
            "           2])}\n",
            "German: zwei junge weiße männer sind im freien in der nähe <unk> büsche .\n",
            "English: two young , white males are outside near many bushes .\n"
          ]
        }
      ],
      "source": [
        "preprocessed_train_dataset = train_dataset.map(\n",
        "    lambda x: preprocess(x, \"de\", \"en\", de_vocab_to_index, en_vocab_to_index),\n",
        "    batched=True,\n",
        "    remove_columns=[\"en\", \"de\"]\n",
        ")\n",
        "preprocessed_train_dataset.set_format(type=\"torch\", columns=[\"source\", \"target\"])\n",
        "\n",
        "print(preprocessed_train_dataset[0])\n",
        "print(f\"German: {decode(de_index_to_vocab, preprocessed_train_dataset[0]['source'].tolist())}\")\n",
        "print(f\"English: {decode(en_index_to_vocab, preprocessed_train_dataset[0]['target'].tolist())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "e1fe5939",
      "metadata": {
        "id": "e1fe5939"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def pad_batch(sequences, pad_idx=0):\n",
        "    dtype = sequences[0].dtype\n",
        "\n",
        "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
        "    max_length = int(lengths.max().item())\n",
        "\n",
        "    padded_batch = torch.full((len(sequences), max_length), pad_idx, dtype=dtype)\n",
        "    for i, seq in enumerate(sequences):\n",
        "        end = lengths[i]\n",
        "        padded_batch[i, :end] = seq\n",
        "    return padded_batch, lengths\n",
        "\n",
        "def collate_fn(batch):\n",
        "    source = [item[\"source\"] for item in batch]\n",
        "    target = [item[\"target\"] for item in batch]\n",
        "\n",
        "    source, source_lengths = pad_batch(source) # defer padding till batching\n",
        "    target, target_lengths = pad_batch(target)\n",
        "\n",
        "    return {\"source\": source, \"source_lengths\": source_lengths, \"target\": target, \"target_lengths\": target_lengths}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "9354221d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9354221d",
        "outputId": "f047d0c9-4117-4d15-8883-7720b3826208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 15])\n",
            "torch.Size([3])\n",
            "torch.Size([3, 16])\n",
            "torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loader = DataLoader(\n",
        "    preprocessed_train_dataset,\n",
        "    batch_size=3,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "\n",
        "batch = next(iter(loader))\n",
        "print(batch[\"source\"].shape)\n",
        "print(batch[\"source_lengths\"].shape)\n",
        "print(batch[\"target\"].shape)\n",
        "print(batch[\"target_lengths\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "337936d3",
      "metadata": {
        "id": "337936d3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout, device, padding_idx=0):\n",
        "        super().__init__()\n",
        "        self.directions = 2\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
        "        self.hidden_projection = nn.Linear(2 * hidden_dim, hidden_dim)\n",
        "        self.cell_projection = nn.Linear(2 * hidden_dim, hidden_dim)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, source_encodings, source_lengths): # source_encodings: (batch_size, max_length), source_lengths: (batch_size)\n",
        "        B, T = source_encodings.size()\n",
        "        h_0 = torch.zeros(self.num_layers * self.directions, B, self.hidden_dim, device=self.device)\n",
        "        c_0 = torch.zeros(self.num_layers * self.directions, B, self.hidden_dim, device=self.device)\n",
        "\n",
        "        embedded = self.embedding(source_encodings) # (B, T, embedding_dim)\n",
        "\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, source_lengths.to('cpu'), batch_first=True, enforce_sorted=False)\n",
        "        packed_outputs, (last_hidden, last_cell) = self.lstm(packed_embedded, (h_0, c_0)) # hidden: (num_layers * directions, B, hidden_dim)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True) # outputs: (B, T, hidden_dim * directions)\n",
        "\n",
        "        h_f = last_hidden[0::2] # (num_layers, B, hidden_dim)\n",
        "        h_b = last_hidden[1::2] # (num_layers, B, hidden_dim)\n",
        "        h_cat = torch.cat((h_f, h_b), dim=2) # (num_layers, B, hidden_dim * 2) concatenate along the hidden dimension\n",
        "\n",
        "        c_f = last_cell[0::2] # (num_layers, B, hidden_dim)\n",
        "        c_b = last_cell[1::2] # (num_layers, B, hidden_dim)\n",
        "        c_cat = torch.cat((c_f, c_b), dim=2) # (num_layers, B, hidden_dim * 2) concatenate along the hidden dimension\n",
        "\n",
        "        last_hidden = torch.tanh(self.hidden_projection(h_cat)) # (num_layers, B, hidden_dim)\n",
        "        last_cell = torch.tanh(self.cell_projection(c_cat)) # (num_layers, B, hidden_dim)\n",
        "\n",
        "        return outputs, last_hidden, last_cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6479c259",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6479c259",
        "outputId": "d118d9c9-8f93-48df-c066-3bfbec26e182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outputs (B, T, hidden_dim * directions): torch.Size([3, 15, 512])\n",
            "last_hidden (num_layers * directions, B, hidden_dim): torch.Size([2, 3, 256])\n",
            "last_cell (num_layers * directions, B, hidden_dim): torch.Size([2, 3, 256])\n",
            "last_hidden: tensor([[[ 2.7087e-02, -6.1209e-02, -1.4815e-02,  ...,  1.9722e-02,\n",
            "          -3.7388e-02, -2.1360e-02],\n",
            "         [ 2.5211e-02, -3.1794e-02, -1.1095e-02,  ...,  1.7036e-02,\n",
            "          -1.7297e-02, -5.8430e-03],\n",
            "         [ 5.5512e-02, -5.2913e-02, -5.8107e-03,  ...,  2.6833e-02,\n",
            "          -1.9347e-02, -4.1027e-02]],\n",
            "\n",
            "        [[-6.8816e-03, -3.6020e-02, -8.7713e-03,  ..., -2.6719e-02,\n",
            "           2.2928e-02,  5.5497e-03],\n",
            "         [-9.2412e-04, -3.9845e-02, -8.9638e-05,  ..., -2.4526e-02,\n",
            "           2.3791e-02,  7.2831e-03],\n",
            "         [-2.3866e-03, -3.6656e-02, -5.3476e-03,  ..., -3.2279e-02,\n",
            "           2.7942e-02,  1.0705e-02]]], grad_fn=<TanhBackward0>)\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(len(de_vocab_to_index), 120, 256, 2, 0.0, 'cpu')\n",
        "\n",
        "outputs, last_hidden, last_cell = encoder(batch[\"source\"], batch[\"source_lengths\"])\n",
        "\n",
        "print(f\"outputs (B, T, hidden_dim * directions): {outputs.shape}\")\n",
        "print(f\"last_hidden (num_layers * directions, B, hidden_dim): {last_hidden.shape}\")\n",
        "print(f\"last_cell (num_layers * directions, B, hidden_dim): {last_cell.shape}\")\n",
        "\n",
        "print(f\"last_hidden: {last_hidden}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "c1101b29",
      "metadata": {
        "id": "c1101b29"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder for the Seq2Seq model. This works on a batch of single step targets (B, 1).\n",
        "    It doesn't take the entire target sequence, because the decision to teacher force and what kind of search strategy to use\n",
        "    is done at the sequence level, not the step level.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout, padding_idx=0):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            bidirectional=False,\n",
        "        )\n",
        "        self.encoder_hidden_projection = nn.Linear(2 * hidden_dim, hidden_dim)\n",
        "        self.encoder_cell_projection = nn.Linear(2 * hidden_dim, hidden_dim)\n",
        "        self.output_projection = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, target, encoder_last_hidden, encoder_last_cell):\n",
        "        # Normalize target shape to (B, 1)\n",
        "        if target.dim() == 0:\n",
        "            target = target.view(1, 1)\n",
        "        else:\n",
        "            target = target.unsqueeze(1)\n",
        "\n",
        "        target = target.long()\n",
        "\n",
        "        embedded = self.embedding(target)  # (B, T, embedding_dim)\n",
        "        # use dropout on the embedded input later\n",
        "        outputs, (hidden, cell) = self.lstm(embedded, (encoder_last_hidden, encoder_last_cell)) # (B, 1, hidden_dim)\n",
        "        logits = self.output_projection(outputs) # (B, 1, vocab_size)\n",
        "\n",
        "        return logits, hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8d68b903",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d68b903",
        "outputId": "a6efaa4d-3a74-4119-f9be-7d1abb827149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3]) tensor([1, 1, 1])\n",
            "logits (B, 1, vocab_size): torch.Size([3, 1, 4560])\n",
            "hidden (num_layers, B, hidden_dim): torch.Size([2, 3, 256])\n",
            "cell (num_layers, B, hidden_dim): torch.Size([2, 3, 256])\n",
            "tensor([[[-0.0045, -0.0050, -0.0049,  ...,  0.0866, -0.0391,  0.0025]],\n",
            "\n",
            "        [[-0.0106, -0.0081, -0.0085,  ...,  0.0898, -0.0361,  0.0049]],\n",
            "\n",
            "        [[-0.0015, -0.0042, -0.0023,  ...,  0.0865, -0.0424,  0.0055]]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder(len(en_vocab_to_index), 120, 256, 2, 0.0)\n",
        "\n",
        "# One decoding step for the whole batch (B,)\n",
        "step0 = batch[\"target\"][:, 0]\n",
        "print(step0.shape, step0)\n",
        "\n",
        "logits, hidden, cell = decoder(step0, last_hidden, last_cell)\n",
        "print(f\"logits (B, 1, vocab_size): {logits.shape}\")\n",
        "print(f\"hidden (num_layers, B, hidden_dim): {hidden.shape}\")\n",
        "print(f\"cell (num_layers, B, hidden_dim): {cell.shape}\")\n",
        "print(logits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "2198a893",
      "metadata": {
        "id": "2198a893"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, bos_idx, eos_idx, max_target_length, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.bos_idx = bos_idx\n",
        "        self.eos_idx = eos_idx\n",
        "        self.max_target_length = max_target_length\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, source, source_lengths, target=None):\n",
        "        B = source.shape[0]\n",
        "\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(source, source_lengths)\n",
        "\n",
        "        if target is not None:\n",
        "            steps = target.shape[1] - 1\n",
        "            inputs = target[:, 0]\n",
        "        else:\n",
        "            steps = self.max_target_length\n",
        "            inputs = torch.full((B,), self.bos_idx, dtype=torch.long)\n",
        "\n",
        "        logits_all = torch.zeros(B, steps, self.decoder.vocab_size, device=self.device)\n",
        "        preds_all = torch.zeros(B, steps, device=self.device)\n",
        "\n",
        "        for t in range(steps):\n",
        "            logits, hidden, cell = self.decoder(inputs, hidden, cell)\n",
        "            step_logits = logits.squeeze(1) # (B, 1, vocab_size) -> (B, vocab_size)\n",
        "            step_preds = step_logits.argmax(dim=1)\n",
        "\n",
        "            logits_all[:, t, :] = step_logits\n",
        "            preds_all[:, t] = step_preds\n",
        "\n",
        "            # Teacher forcing\n",
        "            if target is not None:\n",
        "                inputs = target[:, t + 1]\n",
        "            else:\n",
        "                inputs = step_preds\n",
        "                if step_preds.eq(self.eos_idx).all():\n",
        "                    break\n",
        "\n",
        "        return logits_all, preds_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "f958536b",
      "metadata": {
        "id": "f958536b"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=de_vocab_to_index[PAD])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2d49ab44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d49ab44",
        "outputId": "a7fd0fcc-49d4-4d41-bdcf-56c2448055f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits_all.shape: torch.Size([3, 15, 4560])\n",
            "preds_all.shape: torch.Size([3, 15])\n",
            "batch['target'].shape: torch.Size([3, 16])\n",
            "loss: 8.412188529968262\n",
            "\n",
            "Source: ein junger mann in „ <unk> “ - hemd an einer <unk> .\n",
            "Target: a young man in a \" <unk> \" shirt at a reception desk .\n",
            "Pred: more women dot dot dot dot dot dot dot give computers camcorder wear wear wear\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Source: feuerwehrleute löschen ein feuer .\n",
            "Target: firemen are putting our a fire .\n",
            "Pred: more nails more dot maneuver boxing boxing boxing waterskier waterskier dot dot dot dot dot\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Source: ein grün gekleideter mann springt mit seinem skateboard auf der straße .\n",
            "Target: a man wearing green jumps with his skateboard in the street .\n",
            "Pred: more women freeway operating concert vests maneuver sale maneuver operating descending flooded crystal dot dot\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = Seq2Seq(encoder, decoder, de_vocab_to_index[BOS], de_vocab_to_index[EOS], 30, 'cpu')\n",
        "\n",
        "logits_all, preds_all = model(batch[\"source\"], batch[\"source_lengths\"], batch[\"target\"])\n",
        "target = batch[\"target\"][:, 1:].reshape(-1)\n",
        "loss = criterion(logits_all.reshape(-1, logits_all.shape[-1]), target)\n",
        "\n",
        "\n",
        "print(f\"logits_all.shape: {logits_all.shape}\")\n",
        "print(f\"preds_all.shape: {preds_all.shape}\")\n",
        "print(f\"batch['target'].shape: {batch['target'].shape}\")\n",
        "print(f\"loss: {loss}\\n\")\n",
        "\n",
        "for i in range(len(batch.items())-1):\n",
        "    print(f\"Source: {decode(de_index_to_vocab, batch['source'][i].tolist())}\")\n",
        "    print(f\"Target: {decode(en_index_to_vocab, batch['target'][i].tolist())}\")\n",
        "    print(f\"Pred: {decode(en_index_to_vocab, preds_all[i].tolist())}\")\n",
        "    print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "3979daa1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3979daa1",
        "outputId": "b763ad2b-942b-430f-bd28-c9c7acf57769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "12360bbf",
      "metadata": {
        "id": "12360bbf"
      },
      "outputs": [],
      "source": [
        "tgt_vocab_size = len(en_vocab_to_index) # 4560\n",
        "src_vocab_size = len(de_vocab_to_index) # 5422\n",
        "emb_dim = 512\n",
        "hidden_dim = 512\n",
        "enc_num_layers = 2\n",
        "dec_num_layers = 2\n",
        "enc_dropout = 0.0\n",
        "dec_dropout = 0.0\n",
        "padding_idx = de_vocab_to_index[PAD]\n",
        "bos_idx = de_vocab_to_index[BOS]\n",
        "eos_idx = de_vocab_to_index[EOS]\n",
        "max_target_length = 30\n",
        "\n",
        "batch_size = 64\n",
        "learning_rate = 0.0005\n",
        "epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "3fc59161",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fc59161",
        "outputId": "377476ef-622b-4776-a768-2f1dc696e2d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5422, 512, padding_idx=0)\n",
              "    (lstm): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
              "    (hidden_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (cell_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(4560, 512, padding_idx=0)\n",
              "    (lstm): LSTM(512, 512, num_layers=2, batch_first=True)\n",
              "    (encoder_hidden_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (encoder_cell_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (output_projection): Linear(in_features=512, out_features=4560, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_encoder = Encoder(src_vocab_size, emb_dim, hidden_dim, enc_num_layers, enc_dropout, device, padding_idx)\n",
        "basic_decoder = Decoder(tgt_vocab_size, emb_dim, hidden_dim, dec_num_layers, dec_dropout, padding_idx)\n",
        "\n",
        "basic_model = Seq2Seq(basic_encoder, basic_decoder, bos_idx, eos_idx, max_target_length, device)\n",
        "basic_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad40ae8",
      "metadata": {
        "id": "3ad40ae8"
      },
      "source": [
        "### Model parameter calculation\n",
        "\n",
        "#### Encoder\n",
        "- source embedding: vocab * emb_dim + bias\n",
        "- 2 layers BiLSTM:  \n",
        "    - direction * gates * ( W_x + W_h + b_x + b_h)\n",
        "    - direction * gates * ( W_h + W_h + b_h + b_h)\n",
        "- hidden projection: 2 * (2 * hidden_dim * hidden_dim + b_h)\n",
        "\n",
        "#### Decoder\n",
        "- target embedding: vocab * emb_dim + bias\n",
        "- 2 layers LSTM:\n",
        "    - gates * ( W_x + W_h + b_x + b_h)\n",
        "    - gates * ( W_x + W_h + b_x + b_h)\n",
        "- output projection: hidden_dim * target_vocab + b_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cab4278b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cab4278b",
        "outputId": "3087cd2c-4bca-47bd-92cf-3d68a52c756d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder parameters: 13,334,830\n",
            "Decoder parameters: 8,905,632\n",
            "Seq2Seq parameters: 22,240,462\n"
          ]
        }
      ],
      "source": [
        "p_src_emd = src_vocab_size * emb_dim + src_vocab_size\n",
        "p_enc_lstm_1 = 2 * 4 * (emb_dim * hidden_dim + hidden_dim * hidden_dim + (4*hidden_dim) + (4*hidden_dim))\n",
        "p_enc_lstm_2 = 2 * 4 * (hidden_dim * hidden_dim + hidden_dim * hidden_dim + (4*hidden_dim) + (4*hidden_dim))\n",
        "p_enc_hidden_proj = 2 * (2 * hidden_dim * hidden_dim + hidden_dim)\n",
        "p_enc_cell_proj = 2 * (2 * hidden_dim * hidden_dim + hidden_dim)\n",
        "\n",
        "p_encoder = p_src_emd + p_enc_lstm_1 + p_enc_lstm_2 + p_enc_hidden_proj + p_enc_cell_proj\n",
        "\n",
        "print(f\"Encoder parameters: {p_encoder:,}\")\n",
        "\n",
        "p_tgt_emd = tgt_vocab_size * emb_dim + tgt_vocab_size\n",
        "p_dec_lstm_1 = 4 * (emb_dim * hidden_dim + hidden_dim * hidden_dim + (4*hidden_dim) + (4*hidden_dim))\n",
        "p_dec_lstm_2 = 4 * (hidden_dim * hidden_dim + hidden_dim * hidden_dim + (4*hidden_dim) + (4*hidden_dim))\n",
        "p_dec_output_proj = hidden_dim * tgt_vocab_size + tgt_vocab_size\n",
        "\n",
        "p_decoder = p_tgt_emd + p_dec_lstm_1 + p_dec_lstm_2 + p_dec_output_proj\n",
        "\n",
        "print(f\"Decoder parameters: {p_decoder:,}\")\n",
        "\n",
        "p_seq2seq = p_encoder + p_decoder\n",
        "\n",
        "print(f\"Seq2Seq parameters: {p_seq2seq:,}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9d74caea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d74caea",
        "outputId": "00368597-dee6-40da-a2d4-8f783abadefd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Seq2Seq model has 24,253,904 trainable parameters\n",
            "Encoder parameters: 14,327,808\n",
            "Decoder parameters: 2,895,184\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The Seq2Seq model has {count_parameters(basic_model):,} trainable parameters')\n",
        "print(f\"Encoder parameters: {count_parameters(basic_encoder):,}\")\n",
        "print(f\"Decoder parameters: {count_parameters(decoder):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c9643c2",
      "metadata": {
        "id": "0c9643c2"
      },
      "source": [
        "### Rough estimate of memory needed\n",
        "- long or float32 = 4 bytes\n",
        "- memory for model for Adam optimizer = 4 * mode parameters * 4 bytes\n",
        "- activations of LSTM = 6 * hidden_dim * num_layers * batch_size * seq_len * 4 bytes\n",
        "- activations embedding = batch_size * seq_len * embed_dim * 2\n",
        "- hidden projection activations = batch_size * seq_len * hidden_dim * 2\n",
        "- output project activation = batch_size * seq_len * tgt_vocab\n",
        "\n",
        "total = sum of above + 30%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c166f00a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c166f00a",
        "outputId": "b964ef5f-d676-40b9-8920-84f3bec45e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total memory: 462,906,592 bytes\n",
            "Model memory: 355,847,392 bytes\n",
            "Activations memory: 107,059,200 bytes\n",
            "Total required memory: 601,778,569.6 bytes\n"
          ]
        }
      ],
      "source": [
        "model_memory = 4 * 4 * p_seq2seq\n",
        "activations_memory = 6 * hidden_dim * (enc_num_layers + dec_num_layers) * batch_size * max_target_length * 4\n",
        "embedding_memory = batch_size * max_target_length * emb_dim * 2\n",
        "hidden_projection_memory = batch_size * max_target_length * hidden_dim * 2\n",
        "output_projection_memory = batch_size * max_target_length * tgt_vocab_size\n",
        "\n",
        "total_activations_memory = activations_memory + embedding_memory + hidden_projection_memory + output_projection_memory\n",
        "total_memory = model_memory + total_activations_memory\n",
        "\n",
        "\n",
        "print(f\"Total memory: {total_memory:,} bytes\")\n",
        "print(f\"Model memory: {model_memory:,} bytes\")\n",
        "print(f\"Activations memory: {activations_memory + embedding_memory + hidden_projection_memory + output_projection_memory:,} bytes\")\n",
        "print(f\"Total required memory: {total_memory * 1.3:,} bytes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "b1a9f4df",
      "metadata": {
        "id": "b1a9f4df"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(basic_model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "38001857",
      "metadata": {
        "id": "38001857"
      },
      "outputs": [],
      "source": [
        "def batch_to_device(batch, device):\n",
        "    return {k: v.to(device, non_blocking=True) if isinstance(v, torch.Tensor) else v\n",
        "     for k, v in batch.items()}\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    minutes = int(elapsed_time / 60)\n",
        "    seconds = int(elapsed_time % 60)\n",
        "    return minutes, seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "d3f79912",
      "metadata": {
        "id": "d3f79912"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch_to_device(batch, device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits_all, preds_all = model(batch[\"source\"], batch[\"source_lengths\"], batch[\"target\"])\n",
        "        target = batch[\"target\"][:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(logits_all.reshape(-1, logits_all.shape[-1]), target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "eda839b2",
      "metadata": {
        "id": "eda839b2"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch_to_device(batch, device)\n",
        "        logits_all, preds_all = model(batch[\"source\"], batch[\"source_lengths\"], batch[\"target\"])\n",
        "        target = batch[\"target\"][:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(logits_all.reshape(-1, logits_all.shape[-1]), target)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "7ac2b1fa",
      "metadata": {
        "id": "7ac2b1fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_dataset(\"bentrevett/multi30k\", split=\"train\")\n",
        "val_dataset = load_dataset(\"bentrevett/multi30k\", split=\"validation\")\n",
        "\n",
        "final_train_dataset = train_dataset.map(\n",
        "    lambda x: preprocess(x, \"de\", \"en\", de_vocab_to_index, en_vocab_to_index),\n",
        "    batched=True,\n",
        "    remove_columns=[\"en\", \"de\"]\n",
        ")\n",
        "final_train_dataset.set_format(type=\"torch\", columns=[\"source\", \"target\"])\n",
        "\n",
        "final_val_dataset = val_dataset.map(\n",
        "    lambda x: preprocess(x, \"de\", \"en\", de_vocab_to_index, en_vocab_to_index),\n",
        "    batched=True,\n",
        "    remove_columns=[\"en\", \"de\"]\n",
        ")\n",
        "final_val_dataset.set_format(type=\"torch\", columns=[\"source\", \"target\"])\n",
        "\n",
        "pin_memory = True if device == \"cuda\" else False\n",
        "\n",
        "train_loader = DataLoader(final_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=pin_memory, persistent_workers=True)\n",
        "val_loader = DataLoader(final_val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=pin_memory, persistent_workers=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "336e31d5",
      "metadata": {
        "id": "336e31d5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def save_artifacts(model, train_losses, val_losses, artifacts_path, model_path):\n",
        "    with open(artifacts_path, 'w') as f:\n",
        "        artifacts = {\n",
        "        'train_losses': train_losses,\n",
        "         'val_losses': val_losses,\n",
        "         'batch_size': batch_size,\n",
        "         'learning_rate': learning_rate,\n",
        "         'epochs': epochs,\n",
        "         'model': str(model),\n",
        "         'model_path': model_path,\n",
        "         }\n",
        "        json.dump(artifacts, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8d53ae8e",
      "metadata": {
        "id": "8d53ae8e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def show_graph(train_losses, val_losses, save_path=None, save=False):\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 8))\n",
        "    ax1.plot(train_losses, label='Training loss')\n",
        "    ax1.plot(val_losses, label='Validation loss')\n",
        "    ax1.legend()\n",
        "    ax1.set_title(\"Loss over epochs\")\n",
        "    fig.show()\n",
        "    if save and save_path:\n",
        "        fig.savefig(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "00698da7",
      "metadata": {
        "id": "00698da7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from early_stopping_pytorch import EarlyStopping\n",
        "\n",
        "\n",
        "def train_loop(model, train_loader, val_loader, criterion, optimizer, epochs, model_path, patience=3):\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for e in range(epochs):\n",
        "        start_time = time.time()\n",
        "        train_loss = train(model, train_loader, criterion, optimizer)\n",
        "        val_loss = validate(model, val_loader, criterion)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        if val_loss < best_valid_loss:\n",
        "            best_valid_loss = val_loss\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {e+1}: Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, Epoch time: {epoch_mins}m {epoch_secs}s\")\n",
        "\n",
        "        early_stopping(val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "    return train_losses, val_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "Ber2ilM691gT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ber2ilM691gT",
        "outputId": "67ecb2a7-07cc-4e7a-9b5f-08bd14fcb0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_model_location = '/content/drive/My Drive/ML study/Attentions/additive attention'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "cb5fa701",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb5fa701",
        "outputId": "9bc443a2-89e5-4f2f-dd6a-2bc641dbcc16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train loss: 4.2080, Val loss: 3.5220, Epoch time: 0m 42s\n",
            "Validation loss decreased (inf --> 3.522017).  Saving model ...\n",
            "Epoch 2: Train loss: 3.3890, Val loss: 3.1889, Epoch time: 0m 44s\n",
            "Validation loss decreased (3.522017 --> 3.188903).  Saving model ...\n",
            "Epoch 3: Train loss: 3.0624, Val loss: 2.9446, Epoch time: 0m 42s\n",
            "Validation loss decreased (3.188903 --> 2.944566).  Saving model ...\n",
            "Epoch 4: Train loss: 2.8159, Val loss: 2.7916, Epoch time: 0m 42s\n",
            "Validation loss decreased (2.944566 --> 2.791634).  Saving model ...\n",
            "Epoch 5: Train loss: 2.6113, Val loss: 2.6833, Epoch time: 0m 42s\n",
            "Validation loss decreased (2.791634 --> 2.683342).  Saving model ...\n",
            "Epoch 6: Train loss: 2.4198, Val loss: 2.6212, Epoch time: 0m 43s\n",
            "Validation loss decreased (2.683342 --> 2.621180).  Saving model ...\n",
            "Epoch 7: Train loss: 2.2406, Val loss: 2.5468, Epoch time: 0m 42s\n",
            "Validation loss decreased (2.621180 --> 2.546789).  Saving model ...\n",
            "Epoch 8: Train loss: 2.0636, Val loss: 2.5195, Epoch time: 0m 42s\n",
            "Validation loss decreased (2.546789 --> 2.519492).  Saving model ...\n",
            "Epoch 9: Train loss: 1.8957, Val loss: 2.5304, Epoch time: 0m 42s\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Epoch 10: Train loss: 1.7357, Val loss: 2.5400, Epoch time: 0m 41s\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Epoch 11: Train loss: 1.5783, Val loss: 2.5709, Epoch time: 0m 41s\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "model_path = f'{drive_model_location}/additive-attention-de-en-translator-basic-model.pt'\n",
        "\n",
        "train_losses, val_losses = train_loop(basic_model, train_loader, val_loader, criterion, optimizer, epochs, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b9da3ccc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "b9da3ccc",
        "outputId": "7b22feef-cdec-4b20-fcb1-58c0e170d520"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAKqCAYAAADyoCtDAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjBZJREFUeJzs3Xd4VHXaxvHvzKR3QksgoYceegcpAoIiAjYEFLFgReyF17KWVSxYUOzuwqo0RbEgvSO994ROAqQQSkJ6MnPePwYCkQAJJDkp9+e65iJz5syce7K4zu35zXMshmEYiIiIiIiIlCFWswOIiIiIiIgUNhUdEREREREpc1R0RERERESkzFHRERERERGRMkdFR0REREREyhwVHRERERERKXNUdEREREREpMxR0RERERERkTJHRUdERERERMocFR0RERETLV26FIvFwowZM8yOIiJSpqjoiIiUMJMmTcJisbBhwwazo4iIiJRaKjoiIiIiIlLmqOiIiEipl5KSYnYEEREpYVR0RERKqc2bN3PjjTfi5+eHj48PPXv2ZM2aNbn2ycrK4o033iAsLAwPDw8qVqxIly5dWLBgQc4+sbGx3HfffYSEhODu7k5wcDADBgzg0KFDV8ywePFirrvuOry9vQkICGDAgAHs3r075/EZM2ZgsVhYtmzZRc/9+uuvsVgs7NixI2dbREQEt99+O4GBgXh4eNCmTRv++OOPXM87t7Rv2bJlPPbYY1SpUoWQkJDL5szIyOBf//oX9erVw93dndDQUF544QUyMjJy7WexWBg1ahSTJ0+mQYMGeHh40Lp1a5YvX37Ra+bn9w9w+vRpnn76aWrVqoW7uzshISEMHz6chISEXPs5HA7efvttQkJC8PDwoGfPnuzbty/XPnv37uW2224jKCgIDw8PQkJCuOuuu0hMTLzs+xcRKY9czA4gIiIFt3PnTq677jr8/Px44YUXcHV15euvv6Z79+4sW7aM9u3bA/D6668zduxYHnzwQdq1a0dSUhIbNmxg06ZN9O7dG4DbbruNnTt38sQTT1CrVi3i4+NZsGABUVFR1KpV65IZFi5cyI033kidOnV4/fXXSUtL47PPPqNz585s2rSJWrVq0a9fP3x8fPjpp5/o1q1brudPnz6dJk2a0LRp05z31LlzZ6pXr85LL72Et7c3P/30EwMHDuSXX35h0KBBuZ7/2GOPUblyZV577bXLntFxOBzccsst/P333zz00EM0atSI7du38/HHH7Nnzx5+++23XPsvW7aM6dOnM3r0aNzd3fniiy/o27cv69aty5U1P7//5ORkrrvuOnbv3s39999Pq1atSEhI4I8//uDIkSNUqlQp57jvvvsuVquV5557jsTERN5//32GDRvG2rVrAcjMzKRPnz5kZGTwxBNPEBQUxNGjR5k1axanT5/G39//kr8DEZFyyRARkRJl4sSJBmCsX7/+kvsMHDjQcHNzM/bv35+z7dixY4avr6/RtWvXnG3Nmzc3+vXrd8nXOXXqlAEYH3zwQYFztmjRwqhSpYpx4sSJnG1bt241rFarMXz48JxtQ4YMMapUqWJkZ2fnbIuJiTGsVqvx5ptv5mzr2bOnER4ebqSnp+dsczgcRqdOnYywsLCcbed+P126dMn1mpfyww8/GFar1VixYkWu7V999ZUBGCtXrszZBhiAsWHDhpxthw8fNjw8PIxBgwblbMvv7/+1114zAOPXX3+9KJfD4TAMwzCWLFliAEajRo2MjIyMnMfHjx9vAMb27dsNwzCMzZs3G4Dx888/X/E9i4iIYWjpmohIKWO325k/fz4DBw6kTp06OduDg4MZOnQof//9N0lJSQAEBASwc+dO9u7dm+dreXp64ubmxtKlSzl16lS+M8TExLBlyxZGjBhBYGBgzvZmzZrRu3dvZs+enbNt8ODBxMfHs3Tp0pxtM2bMwOFwMHjwYABOnjzJ4sWLufPOOzlz5gwJCQkkJCRw4sQJ+vTpw969ezl69GiuDCNHjsRms10x688//0yjRo1o2LBhzusmJCRw/fXXA7BkyZJc+3fs2JHWrVvn3K9RowYDBgxg3rx52O32Av3+f/nlF5o3b37R2ShwLpO70H333Yebm1vO/euuuw6AAwcOAOScsZk3bx6pqalXfN8iIuWdio6ISClz/PhxUlNTadCgwUWPNWrUCIfDQXR0NABvvvkmp0+fpn79+oSHh/P888+zbdu2nP3d3d157733mDNnDlWrVqVr1668//77xMbGXjbD4cOHAS6ZISEhIWc5Wd++ffH392f69Ok5+0yfPp0WLVpQv359APbt24dhGLz66qtUrlw51+1f//oXAPHx8bmOU7t27Sv+rsD5vZadO3de9Lrnjv3P1w0LC7voNerXr09qairHjx8v0O9///79OcvdrqRGjRq57leoUAEgp4DWrl2bZ555hu+++45KlSrRp08fPv/8c30/R0TkEvQdHRGRMqxr167s37+f33//nfnz5/Pdd9/x8ccf89VXX/Hggw8C8NRTT9G/f39+++035s2bx6uvvsrYsWNZvHgxLVu2vOYM7u7uDBw4kJkzZ/LFF18QFxfHypUreeedd3L2cTgcADz33HP06dMnz9epV69ervuenp75Or7D4SA8PJyPPvooz8dDQ0Pz9TpF7VJnpwzDyPn5ww8/ZMSIETn/e44ePZqxY8eyZs2aKw5kEBEpb1R0RERKmcqVK+Pl5UVkZORFj0VERGC1WnN9eA8MDOS+++7jvvvuIzk5ma5du/L666/nFB2AunXr8uyzz/Lss8+yd+9eWrRowYcffsiPP/6YZ4aaNWsCXDJDpUqV8Pb2ztk2ePBg/ve//7Fo0SJ2796NYRg5y9aAnCVgrq6u9OrVq4C/kcurW7cuW7dupWfPnhctF8tLXsv89uzZg5eXF5UrVwbI9++/bt26uabKFYbw8HDCw8N55ZVXWLVqFZ07d+arr77i3//+d6EeR0SktNPSNRGRUsZms3HDDTfw+++/5xoBHRcXx5QpU+jSpQt+fn4AnDhxItdzfXx8qFevXs5Y5dTUVNLT03PtU7duXXx9fS8avXyh4OBgWrRowf/+9z9Onz6ds33Hjh3Mnz+fm266Kdf+vXr1IjAwkOnTpzN9+nTatWuXa+lZlSpV6N69O19//TUxMTEXHe/48eOX/6Vcxp133snRo0f59ttvL3osLS3tooltq1evZtOmTTn3o6Oj+f3337nhhhuw2WwF+v3fdtttbN26lZkzZ1507AvP1ORHUlIS2dnZubaFh4djtVov+7+ViEh5pTM6IiIl1H//+1/mzp170fYnn3ySf//73yxYsIAuXbrw2GOP4eLiwtdff01GRgbvv/9+zr6NGzeme/futG7dmsDAQDZs2MCMGTMYNWoU4DxT0bNnT+68804aN26Mi4sLM2fOJC4ujrvuuuuy+T744ANuvPFGOnbsyAMPPJAzXtrf35/XX389176urq7ceuutTJs2jZSUFMaNG3fR633++ed06dKF8PBwRo4cSZ06dYiLi2P16tUcOXKErVu3XsVvEe655x5++uknHnnkEZYsWULnzp2x2+1ERETw008/MW/ePNq0aZOzf9OmTenTp0+u8dIAb7zxRs4++f39P//888yYMYM77riD+++/n9atW3Py5En++OMPvvrqK5o3b57v97F48WJGjRrFHXfcQf369cnOzuaHH37AZrNx2223XdXvRkSkTDN36JuIiPzTufHJl7pFR0cbhmEYmzZtMvr06WP4+PgYXl5eRo8ePYxVq1bleq1///vfRrt27YyAgADD09PTaNiwofH2228bmZmZhmEYRkJCgvH4448bDRs2NLy9vQ1/f3+jffv2xk8//ZSvrAsXLjQ6d+5seHp6Gn5+fkb//v2NXbt25bnvggULDMCwWCw57+Gf9u/fbwwfPtwICgoyXF1djerVqxs333yzMWPGjIt+P5cbv/1PmZmZxnvvvWc0adLEcHd3NypUqGC0bt3aeOONN4zExMSc/QDj8ccfN3788UcjLCzMcHd3N1q2bGksWbLkotfMz+/fMAzjxIkTxqhRo4zq1asbbm5uRkhIiHHvvfcaCQkJhmGcHy/9z7HRBw8eNABj4sSJhmEYxoEDB4z777/fqFu3ruHh4WEEBgYaPXr0MBYuXJjv34OISHliMYwCnjsXEREpoywWC48//jgTJkwwO4qIiFwjfUdHRERERETKHBUdEREREREpc1R0RERERESkzNHUNRERkbP0tVURkbJDZ3RERERERKTMUdEREREREZEyp1QsXXM4HBw7dgxfX18sFovZcURERERExCSGYXDmzBmqVauG1Xrp8zalougcO3aM0NBQs2OIiIiIiEgJER0dTUhIyCUfLxVFx9fXF3C+GT8/P5PTiIiIiIiIWZKSkggNDc3pCJdSKorOueVqfn5+KjoiIiIiInLFr7RoGIGIiIiIiJQ5KjoiIiIiIlLmqOiIiIiIiEiZUyq+oyMiIiIiJZ/dbicrK8vsGFLKubq6YrPZrvl1VHRERERE5JoYhkFsbCynT582O4qUEQEBAQQFBV3TNTRVdERERETkmpwrOVWqVMHLy0sXeJerZhgGqampxMfHAxAcHHzVr6WiIyIiIiJXzW6355ScihUrmh1HygBPT08A4uPjqVKlylUvY9MwAhERERG5aue+k+Pl5WVyEilLzv19upbvfKnoiIiIiMg103I1KUyF8fdJRUdERERERMocFR0RERERkUJQq1YtPvnkk3zvv3TpUiwWS5FPq5s0aRIBAQFFeoySSEVHRERERMoVi8Vy2dvrr79+Va+7fv16HnrooXzv36lTJ2JiYvD397+q48nlaeqaiIiIiJQrMTExOT9Pnz6d1157jcjIyJxtPj4+OT8bhoHdbsfF5cofmytXrlygHG5ubgQFBRXoOZJ/OqMjIiIiIuVKUFBQzs3f3x+LxZJzPyIiAl9fX+bMmUPr1q1xd3fn77//Zv/+/QwYMICqVavi4+ND27ZtWbhwYa7X/efSNYvFwnfffcegQYPw8vIiLCyMP/74I+fxfy5dO7fEbN68eTRq1AgfHx/69u2bq5hlZ2czevRoAgICqFixIi+++CL33nsvAwcOLNDv4Msvv6Ru3bq4ubnRoEEDfvjhh5zHDMPg9ddfp0aNGri7u1OtWjVGjx6d8/gXX3xBWFgYHh4eVK1aldtvv71Axy4uKjoiIiIiUmgMwyA1M9uUm2EYhfY+XnrpJd599112795Ns2bNSE5O5qabbmLRokVs3ryZvn370r9/f6Kioi77Om+88QZ33nkn27Zt46abbmLYsGGcPHnykvunpqYybtw4fvjhB5YvX05UVBTPPfdczuPvvfcekydPZuLEiaxcuZKkpCR+++23Ar23mTNn8uSTT/Lss8+yY8cOHn74Ye677z6WLFkCwC+//MLHH3/M119/zd69e/ntt98IDw8HYMOGDYwePZo333yTyMhI5s6dS9euXQt0/OKipWsiIiIiUmjSsuw0fm2eKcfe9WYfvNwK5+Ptm2++Se/evXPuBwYG0rx585z7b731FjNnzuSPP/5g1KhRl3ydESNGMGTIEADeeecdPv30U9atW0ffvn3z3D8rK4uvvvqKunXrAjBq1CjefPPNnMc/++wzxowZw6BBgwCYMGECs2fPLtB7GzduHCNGjOCxxx4D4JlnnmHNmjWMGzeOHj16EBUVRVBQEL169cLV1ZUaNWrQrl07AKKiovD29ubmm2/G19eXmjVr0rJlywIdv7jojI6IiIiIyD+0adMm1/3k5GSee+45GjVqREBAAD4+PuzevfuKZ3SaNWuW87O3tzd+fn7Ex8dfcn8vL6+ckgMQHBycs39iYiJxcXE5pQPAZrPRunXrAr233bt307lz51zbOnfuzO7duwG44447SEtLo06dOowcOZKZM2eSnZ0NQO/evalZsyZ16tThnnvuYfLkyaSmphbo+MVFZ3REREREpNB4utrY9WYf045dWLy9vXPdf+6551iwYAHjxo2jXr16eHp6cvvtt5OZmXnZ13F1dc1132Kx4HA4CrR/YS7Jy4/Q0FAiIyNZuHAhCxYs4LHHHuODDz5g2bJl+Pr6smnTJpYuXcr8+fN57bXXeP3111m/fn2JG2GtMzoiIiIiUmgsFgtebi6m3CwWS5G9r5UrVzJixAgGDRpEeHg4QUFBHDp0qMiOlxd/f3+qVq3K+vXrc7bZ7XY2bdpUoNdp1KgRK1euzLVt5cqVNG7cOOe+p6cn/fv359NPP2Xp0qWsXr2a7du3A+Di4kKvXr14//332bZtG4cOHWLx4sXX8M6Khs7oiIiIiIhcQVhYGL/++iv9+/fHYrHw6quvXvbMTFF54oknGDt2LPXq1aNhw4Z89tlnnDp1qkAl7/nnn+fOO++kZcuW9OrViz///JNff/01Z4rcpEmTsNvttG/fHi8vL3788Uc8PT2pWbMms2bN4sCBA3Tt2pUKFSowe/ZsHA4HDRo0KKq3fNVUdEREREREruCjjz7i/vvvp1OnTlSqVIkXX3yRpKSkYs/x4osvEhsby/Dhw7HZbDz00EP06dMHmy3/y/YGDhzI+PHjGTduHE8++SS1a9dm4sSJdO/eHYCAgADeffddnnnmGex2O+Hh4fz5559UrFiRgIAAfv31V15//XXS09MJCwtj6tSpNGnSpIje8dWzGMW96O8qJCUl4e/vT2JiIn5+fmbHEREREZGz0tPTOXjwILVr18bDw8PsOOWOw+GgUaNG3Hnnnbz11ltmxyk0l/t7ld9uoDM6IiIiIiKlxOHDh5k/fz7dunUjIyODCRMmcPDgQYYOHWp2tBJHwwiugt1R4k+CiYiIiEgZZLVamTRpEm3btqVz585s376dhQsX0qhRI7OjlTg6o1MAhxJSeH9eBIlpWUx+sIPZcURERESknAkNDb1oYprkTUWnADxcbczbGYfdYbA37gxhVX3NjiQiIiIiInnQ0rUCCPL3oGfDKgBMWXf5q+CKiIiIiIh5VHQKaGj7GgD8svEI6Vl2k9OIiIiIiEheVHQKqGtYZUIqeJKUns2sbTFmxxERERERkTyo6BSQ1WphSDvnWZ3Jaw+bnEZERERERPKionMV7mwTiovVwuao0+w6VvxXxBURERERkctT0bkKlX3d6dMkCIAp63RWR0RERKQ86t69O0899VTO/Vq1avHJJ59c9jkWi4Xffvvtmo9dWK9zOa+//jotWrQo0mMUJRWdqzTs7FCC3zYfIyUj2+Q0IiIiIpJf/fv3p2/fvnk+tmLFCiwWC9u2bSvw665fv56HHnroWuPlcqmyERMTw4033lioxyprVHSuUse6FaldyZvkjGz+3HrM7DgiIiIikk8PPPAACxYs4MiRIxc9NnHiRNq0aUOzZs0K/LqVK1fGy8urMCJeUVBQEO7u7sVyrNJKRecqWSwWhrQLBWDyWl1TR0RERKS0uPnmm6lcuTKTJk3KtT05OZmff/6ZBx54gBMnTjBkyBCqV6+Ol5cX4eHhTJ069bKv+8+la3v37qVr1654eHjQuHFjFixYcNFzXnzxRerXr4+Xlxd16tTh1VdfJSsrC4BJkybxxhtvsHXrViwWCxaLJSfzP5eubd++neuvvx5PT08qVqzIQw89RHJycs7jI0aMYODAgYwbN47g4GAqVqzI448/nnOs/HA4HLz55puEhITg7u5OixYtmDt3bs7jmZmZjBo1iuDgYDw8PKhZsyZjx44FwDAMXn/9dWrUqIG7uzvVqlVj9OjR+T721XAp0lcv425vHcq4eXvYfjSRbUdO0ywkwOxIIiIiIuYyDMhKNefYrl5gsVxxNxcXF4YPH86kSZN4+eWXsZx9zs8//4zdbmfIkCEkJyfTunVrXnzxRfz8/Pjrr7+45557qFu3Lu3atbviMRwOB7feeitVq1Zl7dq1JCYm5vo+zzm+vr5MmjSJatWqsX37dkaOHImvry8vvPACgwcPZseOHcydO5eFCxcC4O/vf9FrpKSk0KdPHzp27Mj69euJj4/nwQcfZNSoUbnK3JIlSwgODmbJkiXs27ePwYMH06JFC0aOHHnF9wMwfvx4PvzwQ77++mtatmzJf//7X2655RZ27txJWFgYn376KX/88Qc//fQTNWrUIDo6mujoaAB++eUXPv74Y6ZNm0aTJk2IjY1l69at+Tru1VLRuQaB3m7cGB7E71uOMWVtlIqOiIiISFYqvFPNnGP/3zFw887Xrvfffz8ffPABy5Yto3v37oBz2dptt92Gv78//v7+PPfcczn7P/HEE8ybN4+ffvopX0Vn4cKFREREMG/ePKpVc/4+3nnnnYu+V/PKK6/k/FyrVi2ee+45pk2bxgsvvICnpyc+Pj64uLgQFBR0yWNNmTKF9PR0vv/+e7y9ne9/woQJ9O/fn/fee4+qVasCUKFCBSZMmIDNZqNhw4b069ePRYsW5bvojBs3jhdffJG77roLgPfee48lS5bwySef8PnnnxMVFUVYWBhdunTBYrFQs2bNnOdGRUURFBREr169cHV1pUaNGvn6PV4LLV27RsPaO/8H/GPrMZLS83/qT0RERETM07BhQzp16sR///tfAPbt28eKFSt44IEHALDb7bz11luEh4cTGBiIj48P8+bNIyoqf19Z2L17N6GhoTklB6Bjx44X7Td9+nQ6d+5MUFAQPj4+vPLKK/k+xoXHat68eU7JAejcuTMOh4PIyMicbU2aNMFms+XcDw4OJj4+Pl/HSEpK4tixY3Tu3DnX9s6dO7N7927AuTxuy5YtNGjQgNGjRzN//vyc/e644w7S0tKoU6cOI0eOZObMmWRnF+1AL53RuUZta1WgXhUf9sUn8/vmo9zTsZbZkURERETM4+rlPLNi1rEL4IEHHuCJJ57g888/Z+LEidStW5du3boB8MEHHzB+/Hg++eQTwsPD8fb25qmnniIzM7PQ4q5evZphw4bxxhtv0KdPH/z9/Zk2bRoffvhhoR3jQq6urrnuWywWHA5Hob1+q1atOHjwIHPmzGHhwoXceeed9OrVixkzZhAaGkpkZCQLFy5kwYIFPPbYYzln1P6Zq7DojM41slgsOaOmJ6+NwjAMkxOJiIiImMhicS4fM+OWj+/nXOjOO+/EarUyZcoUvv/+e+6///6c7+usXLmSAQMGcPfdd9O8eXPq1KnDnj178v3ajRo1Ijo6mpiYmJxta9asybXPqlWrqFmzJi+//DJt2rQhLCyMw4dzX6PRzc0Nu91+xWNt3bqVlJSUnG0rV67EarXSoEGDfGe+HD8/P6pVq8bKlStzbV+5ciWNGzfOtd/gwYP59ttvmT59Or/88gsnT54EwNPTk/79+/Ppp5+ydOlSVq9ezfbt2wslX15UdArBrS1DcHexEhF7hs3Rp82OIyIiIiL54OPjw+DBgxkzZgwxMTGMGDEi57GwsDAWLFjAqlWr2L17Nw8//DBxcXH5fu1evXpRv3597r33XrZu3cqKFSt4+eWXc+0TFhZGVFQU06ZNY//+/Xz66afMnDkz1z61atXi4MGDbNmyhYSEBDIyMi461rBhw/Dw8ODee+9lx44dLFmyhCeeeIJ77rkn5/s5heH555/nvffeY/r06URGRvLSSy+xZcsWnnzySQA++ugjpk6dSkREBHv27OHnn38mKCiIgIAAJk2axH/+8x927NjBgQMH+PHHH/H09Mz1PZ7CpqJTCPy9XLm5mXP95eQ1GjUtIiIiUlo88MADnDp1ij59+uT6Ps0rr7xCq1at6NOnD927dycoKIiBAwfm+3WtViszZ84kLS2Ndu3a8eCDD/L222/n2ueWW27h6aefZtSoUbRo0YJVq1bx6quv5trntttuo2/fvvTo0YPKlSvnOeLay8uLefPmcfLkSdq2bcvtt99Oz549mTBhQsF+GVcwevRonnnmGZ599lnCw8OZO3cuf/zxB2FhYYBzgtz7779PmzZtaNu2LYcOHWL27NlYrVYCAgL49ttv6dy5M82aNWPhwoX8+eefVKxYsVAzXshilIK1VklJSfj7+5OYmIifn5/ZcfK0KeoUt36xCncXK+v+rxf+XkWz1lBERESkJElPT+fgwYPUrl0bDw8Ps+NIGXG5v1f57QY6o1NIWoYG0DDIl4xsB79suvgquyIiIiIiUnxUdAqJxWJhWAfnGsMp6zSUQERERETETCo6hWhgi2p4udnYF5/MuoMnzY4jIiIiIlJuqegUIl8PV25p7vwS25R1GkogIiIiImIWFZ1CNqy9c/nanO2xnEwpvAtKiYiIiJRkWrYvhakw/j6p6BSy8BB/wqv7k2l3MGNjtNlxRERERIrUuavap6ammpxEypJzf5/O/f26Gi6FFUbOG9a+Bi/9up2p66J5sEsdrNaCXaVXREREpLSw2WwEBAQQHx8POK/pYrHos49cHcMwSE1NJT4+noCAAGw221W/lopOEejfvBr//ms3BxNSWH3gBJ3rVTI7koiIiEiRCQoKAsgpOyLXKiAgIOfv1dVS0SkC3u4uDGpZnR/WHGbK2igVHRERESnTLBYLwcHBVKlShaysLLPjSCnn6up6TWdyzlHRKSJD29fghzWHmbczluNnMqjs6252JBEREZEiZbPZCuUDqkhh0DCCItIo2I+WNQLIdhj8tEFDCUREREREipOKThE6N2p66rooHA6NXBQRERERKS4qOkXo5mbB+Hm4cORUGsv3Hjc7joiIiIhIuaGiU4Q8XG3c1joEgClro0xOIyIiIiJSfqjoFLFh7WsAsCgintjEdJPTiIiIiIiUDyo6RaxeFV/a1Q7E7jCYvl5DCUREREREioOKTjE4d1Zn2voosu0Ok9OIiIiIiJR9KjrFoG/TICp4uRKTmM7SSA0lEBEREREpaio6xcDdxcYdbUIBmLJOQwlERERERIqaik4xGdLOuXxtSWQ8R06lmpxGRERERKRsU9EpJrUredO5XkUMAw0lEBEREREpYio6xWhou5oATFsfTZaGEoiIiIiIFJlrKjrvvvsuFouFp5566rL7/fzzzzRs2BAPDw/Cw8OZPXv2tRy21OrduCqVfNw5fiaDRbvjzI4jIiIiIlJmXXXRWb9+PV9//TXNmjW77H6rVq1iyJAhPPDAA2zevJmBAwcycOBAduzYcbWHLrXcXKzc2SYEgMlrNZRARERERKSoXFXRSU5OZtiwYXz77bdUqFDhsvuOHz+evn378vzzz9OoUSPeeustWrVqxYQJE64qcGk3pF0NLBZYsTeBwydSzI4jIiIiIlImXVXRefzxx+nXrx+9evW64r6rV6++aL8+ffqwevXqqzl0qRca6EXXsMoATF2noQQiIiIiIkWhwEVn2rRpbNq0ibFjx+Zr/9jYWKpWrZprW9WqVYmNjb3kczIyMkhKSsp1K0uGtneOmv55QzSZ2RpKICIiIiJS2ApUdKKjo3nyySeZPHkyHh4eRZWJsWPH4u/vn3MLDQ0tsmOZoWfDKlT1c+dESibzdl668ImIiIiIyNUpUNHZuHEj8fHxtGrVChcXF1xcXFi2bBmffvopLi4u2O32i54TFBREXFzuCWNxcXEEBQVd8jhjxowhMTEx5xYdXbaWeLnYrAxu6zyrM3ntYZPTiIiIiIiUPQUqOj179mT79u1s2bIl59amTRuGDRvGli1bsNlsFz2nY8eOLFq0KNe2BQsW0LFjx0sex93dHT8/v1y3suautqFYLbDmwEn2H082O46IiIiISJniUpCdfX19adq0aa5t3t7eVKxYMWf78OHDqV69es53eJ588km6devGhx9+SL9+/Zg2bRobNmzgm2++KaS3UDpVC/Dk+oZVWLg7nqlro3jl5sZmRxIRERERKTOu6YKheYmKiiImJibnfqdOnZgyZQrffPMNzZs3Z8aMGfz2228XFaby6NxQghmbjpCedfGyPxERERERuToWwzAMs0NcSVJSEv7+/iQmJpapZWx2h0HX95dw9HQaHw9uzqCWIWZHEhEREREp0fLbDQr9jI7kn81q4a62zolyk9dEmZxGRERERKTsUNEx2eC2odisFjYcPkVk7Bmz44iIiIiIlAkqOiar4udB70bOC6pO0ahpEREREZFCoaJTApwbSvDr5qOkZWoogYiIiIjItVLRKQG61KtEjUAvzqRn8+e2Y2bHEREREREp9VR0SgCr1cKQds6zOpPXaiiBiIiIiMi1UtEpIe5oE4KrzcLW6NPsOJpodhwRERERkVJNRaeEqOTjTp8mQQBMWaezOiIiIiIi10JFpwQZ1r4mAL9vPkpyRrbJaURERERESi8VnRKkQ51A6lT2JiXTzu9bjpodR0RERESk1FLRKUEsFgtDzw4lmLI2CsMwTE4kIiIiIlI6qeiUMLe1CsHNxcrOY0lsO6KhBCIiIiIiV0NFp4Sp4O1Gv/BgACavPWxyGhERERGR0klFpwQa1t65fO3PrTEkpmWZnEZEREREpPRR0SmBWtesQP2qPqRl2flts4YSiIiIiIgUlIpOCaShBCIiIiIi10ZFp4Qa1CoED1crkXFn2Hj4lNlxRERERERKFRWdEsrf05X+zaoBzrM6IiIiIiKSfyo6JdiwDjUBmLU9htOpmSanEREREREpPVR0SrDmIf40DvYjM9vBjI1HzI4jIiIiIlJqqOiUYBaLhWEdzg4lWKehBCIiIiIi+aWiU8INaFEdbzcbB46nsObASbPjiIiIiIiUCio6JZyPuwu3tKgOOM/qiIiIiIjIlanolALD2juXr83dEUNCcobJaURERERESj4VnVKgaXV/mof4k2U3NJRARERERCQfVHRKiWHtnaOmp66LwuHQUAIRERERkctR0Sklbm4ejK+7C4dPpLJyf4LZcURERERESjQVnVLCy82FW1udHUqwVkMJREREREQuR0WnFBl6dvna/F1xxCelm5xGRERERKTkUtEpRRoE+dK6ZgXsDoOfNkSbHUdEREREpMRS0Sllzo2anrouGruGEoiIiIiI5ElFp5S5KTwYf09Xjp5OY/me42bHEREREREpkVR0ShkPVxu3tw4BYLKGEoiIiIiI5ElFpxQa0s65fG1xRBzHTqeZnEZEREREpORR0SmF6lXxoX3tQBwGTF+voQQiIiIiIv+kolNKDevgHDU9bX0U2XaHyWlEREREREoWFZ1Sqk+TqgR6uxGXlMHiiHiz44iIiIiIlCgqOqWUu4uNO9o4hxJMWaehBCIiIiIiF1LRKcWGtHUOJVi25zjRJ1NNTiMiIiIiUnKo6JRitSp5c11YJQzD+V0dERERERFxUtEp5YaeHTU9ff0RsjSUQEREREQEUNEp9Xo1rkplX3cSkjNYsCvO7DgiIiIiIiWCik4p52qzMrhNKACT1x42OY2IiIiISMmgolMG3NUuFIsFVu47waGEFLPjiIiIiIiYTkWnDAip4EX3+pUBmKpR0yIiIiIiKjplxdD2NQH4eeMRMrLtJqcRERERETGXik4Z0aNBZYL9PTiZksncHbFmxxERERERMZWKThnhYrMyuO25oQRaviYiIiIi5ZuKThkyuG0oVgusO3iSffFnzI4jIiIiImIaFZ0yJNjfk56NqgI6qyMiIiIi5ZuKThkztH0NAH7ZeIT0LA0lEBEREZHySUWnjOkaVpmQCp4kpWfz17YYs+OIiIiIiJhCRaeMsVktDGnnPKszee1hk9OIiIiIiJhDRacMuqNNCC5WC5uiTrM7JsnsOCIiIiIixU5Fpwyq4uvBDU2cQwmmaCiBiIiIiJRDKjpl1NB2NQGYufkoKRnZJqcRERERESleKjplVKe6FalV0YvkjGz+3HrM7DgiIiIiIsVKRaeMsl4wlGDKOi1fExEREZHyRUWnDLu9dQhuNivbjiSy/Uii2XFERERERIqNik4ZVtHHnb5NgwCYsk6jpkVERESk/FDRKeOGtncuX/t9yzHOpGeZnEZEREREpHio6JRx7WsHUreyN6mZdn7boqEEIiIiIlI+qOiUcRaLhaHtnaOmp6yNwjAMkxOJiIiIiBQ9FZ1y4LZW1XF3sbI7Jokt0afNjiMiIiIiUuRUdMqBAC83+jULBmDyWo2aFhEREZGyT0WnnBh2dvnarG3HSEzVUAIRERERKdtUdMqJVjUCaBjkS3qWg183HzE7joiIiIhIkVLRKSecQwmco6Y1lEBEREREyjoVnXJkYMvqeLra2BufzPpDp8yOIyIiIiJSZFR0yhE/D1duaV4NgClrD5ucRkRERESk6KjolDPDOjiXr83eEcvJlEyT04iIiIiIFA0VnXKmWUgATav7kZnt4JeNGkogIiIiImWTik45dG7U9JR1GkogIiIiImWTik45dEvzavi4u3AwIYXV+0+YHUdEREREpNCp6JRD3u4uDGjhHEoweV2UyWlERERERAqfik45dW752rwdsRw/k2FyGhERERGRwqWiU041ruZHi9AAsh0GP2+MNjuOiIiIiEihUtEpx4a1d46anrouCodDQwlEREREpOxQ0SnHbm5WDV8PF6JPprFiX4LZcURERERECo2KTjnm6WbjtlYhAExZe9jkNCIiIiIihUdFp5wbenb52sLd8cQlpZucRkRERESkcKjolHP1q/rStlYF7A6D6es1lEBEREREygYVHckZNT1tXRR2DSUQERERkTJARUfo2zSICl6uHEtMZ2lkvNlxRERERESumYqO4OFq4/bW54YSRJmcRkRERETk2qnoCABD2jmHEiyJjOfo6TST04iIiIiIXBsVHQGgTmUfOtapiMOA6et0VkdERERESjcVHckxrIPzrM609dFk2R0mpxERERERuXoqOpLjhsZBVPJxI/5MBot2ayiBiIiIiJReKjqSw83Fyh1tQgGYvPawyWlERERERK6eio7kMqStc/nair0JRJ1INTmNiIiIiMjVUdGRXGpU9KJr/coATF2voQQiIiIiUjqp6MhFhp4dNf3zhmgyszWUQERERERKHxWdgrJng2GYnaJI9WxUhSq+7iQkZzJ/V6zZcURERERECkxFpyDs2fDrgzDnxTJddlxtVu5qe3YowRotXxMRERGR0kdFpyAO/w07Z8K6r2HumDJddga3q4HVAqsPnGD/8WSz44iIiIiIFEiBis6XX35Js2bN8PPzw8/Pj44dOzJnzpxL7j9p0iQsFkuum4eHxzWHNk2d7nDLZ86f134J8/6vzJad6gGe9GhQBYCpa3VWR0RERERKlwIVnZCQEN599102btzIhg0buP766xkwYAA7d+685HP8/PyIiYnJuR0+XMqvz9JqOPQf7/x5zRcw/5UyW3aGtncOJZix6QjpWXaT04iIiIiI5J9LQXbu379/rvtvv/02X375JWvWrKFJkyZ5PsdisRAUFHT1CUui1iOc5WbWU7B6Algs0Pst559lSPcGVajm78GxxHTm7ohlYMvqZkcSEREREcmXq/6Ojt1uZ9q0aaSkpNCxY8dL7pecnEzNmjUJDQ294tmfczIyMkhKSsp1K3Ha3Af9PnL+vOozWPBamTuzY7NauOvsqOnJa0v5mTgRERERKVcKXHS2b9+Oj48P7u7uPPLII8ycOZPGjRvnuW+DBg3473//y++//86PP/6Iw+GgU6dOHDly5LLHGDt2LP7+/jm30NDQgsYsHm0fgJvGOX9e9SksfL3MlZ3BbUOxWS2sP3SKPXFnzI4jIiIiIpIvFsMo2CfzzMxMoqKiSExMZMaMGXz33XcsW7bskmXnQllZWTRq1IghQ4bw1ltvXXK/jIwMMjIycu4nJSURGhpKYmIifn5+BYlbPNZ9C7Ofc/7c5Rno+VqZWsb28A8bmLczjhGdavH6LXkvURQRERERKQ5JSUn4+/tfsRsU+IyOm5sb9erVo3Xr1owdO5bmzZszfvz4fD3X1dWVli1bsm/fvsvu5+7unjPZ7dytRGs3Em583/nz3x/B4n+XqTM7Q9vXBOCXTUdIy9RQAhEREREp+a75OjoOhyPX2ZfLsdvtbN++neDg4Gs9bMnT/mHo+67z5xXjYMnbZabsXFevEqGBnpxJz+bPbcfMjiMiIiIickUFKjpjxoxh+fLlHDp0iO3btzNmzBiWLl3KsGHDABg+fDhjxozJ2f/NN99k/vz5HDhwgE2bNnH33Xdz+PBhHnzwwcJ9FyVFh0ehz1jnz8s/gKXvmpunkFitFoacHUowRdfUEREREZFSoEDjpePj4xk+fDgxMTH4+/vTrFkz5s2bR+/evQGIiorCaj3fnU6dOsXIkSOJjY2lQoUKtG7dmlWrVuXr+zylVsfHAMN5MdFl7zq/q9P9JbNTXbM7Wofy0fw9bIk+zc5jiTSp5m92JBERERGRSyrwMAIz5PcLRyXKqs+cFxMF6PEydHvB3DyF4PEpm/hrWwzD2tfg7UHhZscRERERkXKoyIYRSD51egJ6v+n8ecnbsOwDc/MUgmFnl6/9tvkoyRnZJqcREREREbk0FZ2i1PlJ6PW68+cl/4bl40yNc6061q1InUrepGTa+WOLhhKIiIiISMmlolPUujwNPf/l/HnxW7DiI3PzXAOL5YKhBOsOm5xGREREROTSVHSKw3XPwPWvOn9e9Ab8/Ympca7Fba1DcHOxsuNoEtuOnDY7joiIiIhInlR0ikvX56DH2eEEC/8FK/N3kdWSJtDbjZuaBgEweY1GTYuIiIhIyaSiU5y6PQ/d/8/584LXnJPZSqGh7WsC8MfWYySlZ5mcRkRERETkYio6xa37i9D97EVV578Cqz83N89VaFurAmFVfEjLsvPb5qNmxxERERERuYiKjhm6vwTdXnT+PO//YPUX5uYpIIvFwtD2Z4cSrI2iFFyKSURERETKGRUds3QfA12fd/48bwys+crcPAV0a8sQPFytRMSeYVPUKbPjiIiIiIjkoqJjFosFerwM1z3rvD/3RVj7jbmZCsDfy5Wbm1UDYPJaDSUQERERkZJFRcdMFotz7HSXZ5z35zwP6741N1MBDDu7fO2vbTGcTs00OY2IiIiIyHkqOmazWKDna9D5Kef92c/B+u9MjZRfLUIDaBTsR0a2g182aSiBiIiIiJQcKjolgcUCvV6HTqOd9/96Ftb/x9RI+ZF7KMFhDSUQERERkRJDRaeksFig95vQ6Qnn/b+egQ0Tzc2UDwNbVMPLzcb+4ymsPXjS7DgiIiIiIoCKTslisUDvt6DjKOf9WU/Bxv+ZGulKfD1cGdDCOZRgioYSiIiIiEgJoaJT0lgscMO/ocNjzvt/joZN35ub6QqGtqsJwJwdMZxIzjA5jYiIiIiIik7JZLFAn3eg/aPO+3+Mhk0/mJvpMsJD/GkW4k+W3eDFX7aTme0wO5KIiIiIlHMqOiWVxQJ9x0K7hwED/ngCNk82O9Ul/d9NjXBzsbJwdxyP/riRjGy72ZFEREREpBxT0SnJLBa48T1oOxIw4PfHYctUs1PlqUOdivzn3ja4u1hZFBHPwz9sJD1LZUdEREREzKGiU9JZLHDTB9DmAcCA3x6FrdPMTpWn68IqM3FEWzxcrSyNPM5DKjsiIiIiYhIVndLAYoGbxkGb+wEDZj4CW6ebnSpPnepVYuKIdni62li+5zgjv99AWqbKjoiIiIgULxWd0sJqhZs+hNb34Tyz8whs+9nsVHnqWLcik+5ri5ebjRV7E3jgf+tJzcw2O5aIiIiIlCMqOqWJ1Qr9PoJW94LhgJkPwfYZZqfKU/s6Ffnf/e3wdrOxav8J7p+ksiMiIiIixUdFp7SxWuHmT6DlPc6y8+tI2PGL2any1LZWIN8/0A4fdxfWHDjJiP+uJyVDZUdEREREip6KTmlktUL/T6Hl3c6y88tI2PGr2any1Lqms+z4uruw7tBJ7v3vOpJVdkRERESkiKnolFZWK/T/DFoMA8MOvzwIO38zO1WeWtWowI8PtsfPw4UNh08x/D9rSUrPMjuWiIiIiJRhKjqlmdUKt3wGzYc6y86M+2HX72anylPz0AAmP9gBf09XNkWdZvh/1qnsiIiIiEiRUdEp7aw2GDABmt11vuzs/tPsVHkKD/Fn8oPtCfByZUv0ae75bi2JaSo7IiIiIlL4VHTKAqsNBn4BzQaDIxt+HgG7Z5mdKk9Nq/sz5cEOVPByZeuRRO7+bi2nUzPNjiUiIiIiZYyKTllhtcHALyH8jrNl516I+MvsVHlqXM2PqQ91oKK3G9uPJjL027WcSlHZEREREZHCo6JTllhtMPAraHq7s+z8dC9EzjE7VZ4aBjnLTiUfN3bFJDH0u7WcVNkRERERkUKiolPW2Fxg0NfQ5FZwZMH0eyByrtmp8lS/qi9TR3agko87u2OSGPrtGk4kZ5gdS0RERETKABWdssjmArd+C00GOcvOT/fAnnlmp8pTWFVfpj3UgSq+7kTEnmHIt2s4fkZlR0RERESujYpOWWVzgVu/g8YDwZ4J0++GvQvMTpWnelV8mPZQB6r6ubMnLpkh364h/ky62bFEREREpBRT0SnLbC5w23fQ6BZn2Zk2DPYuNDtVnupU9mH6Qx0J9vdgX3wyd32zhrgklR0RERERuToqOmWdzRVu/y80vBnsGTBtKOwrmWWnViVvpj3UgWr+Hhw4nsJd36whNlFlR0REREQKTkWnPLC5wu0Tz5edqUNh3yKzU+WpZkVvpj/ckeoBnhxMSGHwN6s5djrN7FgiIiIiUsqo6JQXLm7OstOg3/kzO/uXmJ0qT6GBXkx7qAOhgZ4cPpHKXd+s4ajKjoiIiIgUgIpOeeLiBndMgvo3QnY6TL0LDiw1O1WenGWnIzUCvYg6mcrgr1cTfTLV7FgiIiIiUkqo6JQ3Lm5w5/+gfl9n2ZlyFxxYZnaqPFUP8GT6wx2oVdGLI6fSuOubNSo7IiIiIpIvKjrlkYs73Pk9hPWB7DSYMhgOrjA7VZ6C/T2Z9lBH6lTy5ujpNAZ/vZrDJ1LMjiUiIiIiJZyKTnnl4g6Df4CwG86WnTvh0N9mp8pTkL8H0x7qQN3K3hxLTGfw12s4mKCyIyIiIiKXpqJTnrm4w50/QL1ekJUKk++AQyvNTpWnKn4eTH2oA2FVfIhNSueub1az/3iy2bFEREREpIRS0SnvXD1g8GSoe/35snN4ldmp8lTF11l26lf1IS4pg7u+WcO+eJUdEREREbmYio44y85dU6BOD8hKgR9vh8OrzU6Vp0o+7kwd2YGGQb4cP+MsO3vjzpgdS0RERERKGBUdcXL1hCFToU53Z9mZfDtErTU7VZ4q+rgzZWQHGgf7kZDsLDuRsSo7IiIiInKeio6c5+oJd02F2t0gMxl+vA2i15mdKk+B3m5MGdmeJtX8OJGSyZBv17A7JsnsWCIiIiJSQqjoSG5uXjBkGtS6DjLPwA+3QvR6s1PlKcDLjSkPdiC8uj8nUzIZ+u0adh5LNDuWiIiIiJQAKjpyMTcvGDr9fNn58VY4ssHsVHny93Llxwfb0zw0gFOpWQz7bi07jqrsiIiIiJR3KjqSNzdvZ9mp2QUykuCHQXBko9mp8uTv6coPD7SjZY0ATqdmMfTbNWw7ctrsWCIiIiJiIhUduTQ3bxj2E9TsfL7sHC2ZZcfPw5Xv729H65oVSErPZth3a9kSfdrsWCIiIiJiEhUduTw3bxj6E9ToCBmJ8P0gOLrJ7FR58vVw5X/3t6NtrQqcSc/mnu/WsinqlNmxRERERMQEKjpyZe4+MOxnCO3gLDs/DIRjW8xOlScfdxcm3deOdrUDOZORzfD/rGPj4ZNmxxIRERGRYqaiI/nj7gt3z4DQ9pCeCN8PgJitZqfKk7e7C5Pua0vHOhVJPlt21h9S2REREREpT1R0JP/cfWHYDAhpB+mnz5adbWanypOXmwv/HdGWzvUqkpJp597/rmPtgRNmxxIRERGRYqKiIwXj4Qd3/wIhbSHtFHx/C8RuNztVnjzdbPzn3rZcF1aJ1Ew7IyauZ9X+BLNjiYiIiEgxUNGRgjtXdqq3cZad/90CsTvMTpUnD1cb3w5vQ7f6lUnLsnP/pPWs3KeyIyIiIlLWqejI1fHwh3t+heqtIe2k88xO3E6zU+XJw9XG1/e0pkeDyqRnObh/0nqW7zludiwRERERKUIqOnL1PPzh7l+hWktIPQH/6w/R681OlScPVxtf3dOaXo2qkJHt4MHvN7A0Mt7sWCIiIiJSRFR05Np4BsA9MyG4hbPsTOwLK8eDw2F2sou4u9j4YlhrejeuSma2g4e+38iSCJUdERERkbJIRUeunWcFuPdPaDIIHNmw4DWYcieklLzvwri5WPl8aCv6Ngki0+7goR82sHBXnNmxRERERKSQqehI4fDwg9snws2fgIsH7FsAX3aGg8vNTnYRNxcrnw1tSb/wYLLsBo9O3sj8nbFmxxIRERGRQqSiI4XHYoE298HIxVCpASTHOieyLXkHHHaz0+XiarMy/q4W3NzMWXYem7yJuTtizI4lIiIiIoVERUcKX9Um8NASaHk3YMCy95yDCpKOmZ0sFxeblU8Gt2BAi2pkOwwen7KZv7ap7IiIiIiUBSo6UjTcvGHA53Drd+DmA4dXOpey7ZlndrJcXGxWPrqzBbe2rI7dYTB62mb+3FqyCpmIiIiIFJyKjhStZnfAw8shuLnzejtT7oR5L0N2ptnJctisFj64ozm3tw7B7jB4ctpmft9y1OxYIiIiInINVHSk6FWsCw8sgPaPOO+vngD/7QMnD5qb6wI2q4X3b2vGnW1CcBjw9PQtzNx8xOxYIiIiInKVVHSkeLi4w43vwV1TwCMAjm2Cr7vCjl/NTpbDarXw7q3NGNIuFIcBz/y0lRkbVXZERERESiMVHSleDfvBI39DaAfISIIZ98GfT0FWmtnJAGfZeXtgOHd3qIFhwPMztvLT+mizY4mIiIhIAanoSPELCIURf8F1zwIW2DgRvu0JxyPNTgY4y85bA5oyvGNNDANe+GUbU9dFmR1LRERERApARUfMYXOBnq/BPb+CdxWI3wnfdIfNP4JhmJ0Oi8XCG7c0YUSnWgCM+XU7P645bG4oEREREck3FR0xV93rnUvZ6nSHrFT4/XH49SHIOGN2MiwWC//q35gHutQG4JXfdvD96kPmhhIRERGRfFHREfP5VoW7Z8L1r4LFBtt/gq+7QcxWs5NhsVh4pV8jHu5aB4DXft/JxJUlZ1qciIiIiORNRUdKBqsVuj4H980GvxA4uR++6wVrvzZ9KZvFYuGlGxvyaPe6ALzx5y6+W3HA1EwiIiIicnkqOlKy1OgAj6yABjeBPRPmvADT74bUk6bGslgsvNCnAaN61APg33/t5pvl+03NJCIiIiKXpqIjJY9XoPN6O33fA5sbRMxyXnMnaq2psSwWC8/eUJ/RPcMAeGd2BF8uVdkRERERKYlUdKRksligwyPwwAIIrAOJ0TDxRljxITgcJsay8Ezv+jzdqz4A782NYMLivablEREREZG8qehIyVatBTy8HMLvAMMOi96EH2+F5HhTYz3ZK4znbnCWnXHz9zB+ocqOiIiISEmioiMln7sv3Pot3DIBXDzhwBL4sjPsX2JqrFHXh/FC3wYAfLxwDx8v2INRAq4BJCIiIiIqOlJaWCzQ6h54aClUaQwp8fDDIFj0FtizTYv1WPd6jLmxIQDjF+3lI5UdERERkRJBRUdKlyoNYeRiaD0CMGDFOJjUDxKPmBbp4W51eaVfIwA+W7yP9+dFquyIiIiImExFR0ofV0/oPx5u/y+4+0H0GviqC0TMNi3Sg9fV4bWbGwPw5dL9vDsnQmVHRERExEQqOlJ6Nb3NOaigWktIOwXThsCclyA7w5Q493epzZsDmgDw9fIDvP3XbpUdEREREZOo6EjpFlgb7p8PHR533l/7JfynN5ww5/o2wzvW4t8DmwLw3d8HeXPWLpUdEREREROo6Ejp5+IGfd+BIdPBMxBitsLX3WD7DFPi3N2hJu8MCgdg4spDvP7HTpUdERERkWKmoiNlR4O+8MjfUKMTZJ6BXx6A30dBZmqxRxnavgbv3RaOxQL/W32YF3/ZRnqWvdhziIiIiJRXKjpStvhXh3v/hK4vABbY/AN82wPidhV7lMFta/D+bc2wWOCnDUe49YtVHExIKfYcIiIiIuWRio6UPTYXuP5lGP47+FSF4xHOsrNxEhTzErI72oQy6b52VPR2Y1dMEjd/uoLftxwt1gwiIiIi5ZGKjpRddbrBIyuhbk/IToc/n4QZ90N6UrHG6Fa/MrOfvI72tQNJybTz5LQtjPlVS9lEREREipKKjpRtPpVh2Azo9QZYXWDnr/D1dXB0U7HGqOrnweQH2zO6ZxgWC0xdF82ACSvZF3+mWHOIiIiIlBcqOlL2Wa3Q5Sm4by7414BTh+A/N8Dqz4t1KZuLzcozvevz4wPtqeTjTmTcGfp/tpJfNh4ptgwiIiIi5YWKjpQfoW3hkeXQqD84smDe/8HUuyD1ZLHG6FyvErOf7ELnehVJy7Lz7M9bee7nraRmZhdrDhEREZGyTEVHyhfPCnDnD3DTOLC5w5658FUXOLyqWGNU8fXg+/vb82zv+lgtMGPjEW6ZsJLIWC1lExERESkMKjpS/lgs0G4kPLgQKtaDpKMwqR8s+wAcxTcgwGa18ETPMKaM7EBVP3f2xSdzy4S/mb4+ShcYFREREblGKjpSfgU3g4eWQfMhYDhgyb/hh4FwJrZYY3SoU5HZo6+jW/3KZGQ7ePGX7Tw9fQvJGVrKJiIiInK1ClR0vvzyS5o1a4afnx9+fn507NiROXPmXPY5P//8Mw0bNsTDw4Pw8HBmz559TYFFCpW7Dwz6CgZ+Ba7ecHA5fNkZ9i0s1hgVfdyZOKItL/ZtiM1q4bctx7jls7/ZeSyxWHOIiIiIlBUFKjohISG8++67bNy4kQ0bNnD99dczYMAAdu7cmef+q1atYsiQITzwwANs3ryZgQMHMnDgQHbs2FEo4UUKTYsh8NBSqNoUUhPgx9tgwb/AnlVsEaxWC492r8tPD3egmr8HBxJSGPTFKn5Yc1hL2UREREQKyGJc4yeowMBAPvjgAx544IGLHhs8eDApKSnMmjUrZ1uHDh1o0aIFX331Vb6PkZSUhL+/P4mJifj5+V1LXJHLy0qDeS/Dhv8474e0g9v/AwE1ijXGqZRMnp+xlYW74wHo1yyYsbeG4+fhWqw5REREREqa/HaDq/6Ojt1uZ9q0aaSkpNCxY8c891m9ejW9evXKta1Pnz6sXr36ag8rUrRcPeHmj+DO78HdH46sc05l2/1nscao4O3Gt8Pb8Eq/RrhYLfy1LYabP/2bbUdOF2sOERERkdKqwEVn+/bt+Pj44O7uziOPPMLMmTNp3LhxnvvGxsZStWrVXNuqVq1KbOzlv+ydkZFBUlJSrptIsWo8wHnNneptID0Rpt8Nfz0HWenFFsFisfDgdXWY8WgnQip4EnUyldu+XMXElQe1lE1ERETkCgpcdBo0aMCWLVtYu3Ytjz76KPfeey+7du0q1FBjx47F398/5xYaGlqory+SLxVqwf1zodNo5/3138J/ekHCvmKN0SI0gL9GX0efJlXJshu88ecuHv5hI4mpxff9IREREZHSpsBFx83NjXr16tG6dWvGjh1L8+bNGT9+fJ77BgUFERcXl2tbXFwcQUFBlz3GmDFjSExMzLlFR0cXNKZI4bC5wg1vwbAZ4FURYrfD111h67RijeHv6cpXd7fmjVua4GazMn9XHDd9uoLNUaeKNYeIiIhIaXHN19FxOBxkZGTk+VjHjh1ZtGhRrm0LFiy45Hd6znF3d88ZYX3uJmKqsN7wyEqodR1kpcDMh2Hmo5CRXGwRLBYL93aqxS+PdqJmRS+Onk7jjq9W8+3yAzgcWsomIiIicqECFZ0xY8awfPlyDh06xPbt2xkzZgxLly5l2LBhAAwfPpwxY8bk7P/kk08yd+5cPvzwQyIiInj99dfZsGEDo0aNKtx3IVIc/IJh+O/Q/f/AYoWtU+DbHhBbvOPSw0P8mfVEF/o1CybbYfD27N08+P0GTqVkFmsOERERkZKsQEUnPj6e4cOH06BBA3r27Mn69euZN28evXv3BiAqKoqYmJic/Tt16sSUKVP45ptvaN68OTNmzOC3336jadOmhfsuRIqL1QbdX4R7/wTfYEjYA99eD+v/A8U4IMDXw5UJQ1ry9qCmuLlYWRwRz02frmDDoZPFlkFERESkJLvm6+gUB11HR0qklBPw26Owd57zfuMB0P9T8Awo1hi7jiUxasomDiSkYLNaeKZ3fR7tVher1VKsOURERESKQ5FfR0ek3POuCEOmwQ1vg9UVdv0OX18HRzYWa4zG1fz484kuDGpZHbvD4IN5kYyYtJ6E5Ly/OyciIiJSHqjoiFwLqxU6jYL750FATTgdBf+9AVZ+Cg5HscXwdnfhozub8/5tzfBwtbJ8z3FuGr+CNQdOFFsGERERkZJERUekMIS0hkdWQOOB4MiGBa/ClDshJaHYIlgsFu5sG8ofo7oQVsWH+DMZDP12DeMX7sWuqWwiIiJSzqjoiBQWD3+4YxLc/Am4eMC+BfBVFzi4olhj1K/qy++jOnNH6xAcBny8cA/3/Gct8WfSizWHiIiIiJlUdEQKk8UCbe6DkYuhUn04EwPf3wLzXoYzscUWw8vNhQ/uaM5HdzbHy83Gqv0nuGn8Cv7eW3xnmERERETMpKlrIkUlMwVmvwBbfnTet7lB87ug02ioFFZsMfbFJzNqyiYiYs9gscCoHvV4smcYLjb9dw4REREpffLbDVR0RIrannmw4kOIXnt2gwUa9oPOT0Fo22KJkJ5l540/dzF1XRQA7WoH8uldLQny9yiW44uIiIgUFhUdkZImag2sHA+Rs89vq9kZOj8J9Xo7J7gVsT+2HmPML9tIybQT6O3GR3c2p3uDKkV+XBEREZHCoqIjUlIdj3SOn942HRxZzm2VGzkLT9PbwMWtSA9/MCGFUVM2sfNYEgCPdKvLszfUx1VL2URERKQUUNERKemSjsGaL2HDRMg849zmVx06PAat7wV33yI7dHqWnXdm7+b71YcBaF2zAp8OaUn1AM8iO6aIiIhIYVDRESkt0k7DxonO0pMc59zm4Q9tH4T2j4BP0S0tm7M9hhd+2caZ9Gz8PV358I7m9GpctciOJyIiInKtVHRESpusdOdytlWfwol9zm02d2gxFDo9ARXrFslho06k8sTUTWw9kgjAg11q80Lfhri5aCmbiIiIlDwqOiKllcMBkX/B35/A0Q1nN1qgUX/o8hRUb13oh8zMdvDunAj+u/IgAM1DA5gwpCWhgV6FfiwRERGRa6GiI1LaGQZErXZOatsz9/z2WtedndTWy3mB0kK0YFccz/28lcS0LHw9XPjg9mb0bRpcqMcQERERuRYqOiJlSdwuWPUZbP8JHNnObVWanJ3UdivYXAvtUEdOpTJ66mY2RZ0G4N6ONfm/fo1wd7EV2jFERERErpaKjkhZlHjEObRg4yTITHZu8w+Fjo9Dy3vA3adQDpNldzBufiRfLzsAQNPqfkwY0opalbwL5fVFRERErpaKjkhZlnYK1v8H1n4FKced2zwCoN1DzptP5UI5zJKIeJ75aQunUrPwcXdh7K3h9G9erVBeW0RERORqqOiIlAdZ6bB1qnNS20nn2RdcPKDFMOg0CgLrXPMhYhLTeHLqFtYdOgnA0PY1eO3mxni4aimbiIiIFD8VHZHyxGGHiFnOSW3HNjm3WazQeIDzezzVWl7Ty2fbHXyycC+fL92HYUDDIF8+H9aKupULZ6mciIiISH6p6IiUR4YBh1c6C8++Bee31+4KnZ+Cutdf06S2FXuP8/T0LSQkZ+LlZuPtQU0Z1DLkmmOLiIiI5JeKjkh5F7vDOaltx4zzk9qCwp2Fp/FAsLlc1cvGJ6Xz5LQtrD5wAoA7Wofw5oCmeLppKZuIiIgUPRUdEXE6HQ1rvoCN/4OsFOe2gBrQcRS0vBvcCj5Jze4w+GzxXsYv2othQFgVHz4f1or6VX0LObyIiIhIbio6IpJb6snzk9pSE5zbPAPPT2rzrljgl1y1P4Enp23h+JkMPFytvDmgKXe0DsFSyBcyFRERETlHRUdE8paVBlsmO5e1nTrk3Obi6Ty702kUVKhVoJdLSM7g6elbWLHXWZ4GtazOvwc2xdv96pbGiYiIiFyOio6IXJ7DDrv/cA4uiNni3GaxQpNBzkltwc3z/1IOgy+X7efD+ZE4DKhTyZvPh7WiUbD+eRUREZHCpaIjIvljGHBwOawcD/sXnd9ep4ez8NTpnu9JbesOnmT01M3EJqXj5mLlX/0bM7RdDS1lExERkUKjoiMiBRezzXnx0R2/gmF3bgtu7iw8jQbka1LbyZRMnv1pC0sijwNwc7Ngxt4ajq+Ha1EmFxERkXJCRUdErt6pw7D6c9j0PWSnObdVqOWc1NZiGLh5XfbpDofBtysO8MG8SLIdBjUrevH50FY0re5f9NlFRESkTFPREZFrl3IC1n8H676GVOd1c/CqCO0ehnYjwSvwsk/fePgUo6du5ujpNNxsVl7u14jhHWtqKZuIiIhcNRUdESk8mannJ7WdPuzc5uoFrYZDx8ed1+W5hNOpmTz38zYW7o4DoG+TIN67vRn+nlrKJiIiIgWnoiMihc+eDbt/d05qi93m3GaxQdPboPNoCArP82mGYTBx5SHGztlNlt0gpIInE4a2okVoQLFFFxERkbJBRUdEio5hwIGlzkltB5ac3163J3R5Cmpdl+ektq3Rpxk1dRPRJ9NwtVl4sW9D7u9cG6tVS9lEREQkf1R0RKR4HNvinNS2cyYYDue2ai3PTmq7Bay2XLsnpmXx0i/bmLMjFoDWNSvw9qCmNAzSP9siIiJyZSo6IlK8Th50Tmrb/OMFk9pqQ6cnoMVQcPXM2dUwDH5cG8XY2btJzbTjYrXwwHW1ebJnGF5uVx5hLSIiIuWXio6ImCMlAdZ947ylnXJu864M7R+GNg/kmtR27HQab/y5k3k7nYMKqgd48sYtTejVuKoZyUVERKQUUNEREXNlpjjP7qyaAIlRzm2u3tD6XujwGASE5uy6cFcc//pjJ0dPO88E9WlSlX/1b0K1AM+8XllERETKMRUdESkZ7NnO7++sHA9x253brC7Q9HbnsragpgCkZmYzftFe/rPiINkOAy83G8/0rs+ITrVwsVlNfAMiIiJSkqjoiEjJYhiwfzGs/AQOLj+/vWpTaDzAObigSkMiYpN4eeYONh52LntrFOzHO4Oa0rJGBXNyi4iISImioiMiJdfRTc4zPBGzwJF9fnulBtB4AI5Gt/BTlB9j50aSmJaFxQLD2tfg+T4NdaFRERGRck5FR0RKvtSTEDkHdv3uPNvjyDr/WGBdUsNu5uv4pozf7QVYqOTjzqs3N+KW5tWw5HGdHhERESn7VHREpHRJOw175jlLz76FYM/IeSjdO4TfM9swNbkVW4y6dKlXmbcGNqV2JW/z8oqIiIgpVHREpPTKOAN75ztLz94FkJWa89AxoyJz7W1ZQAfad7uRR3uE4e5iu8yLiYiISFmioiMiZUNmqvMMz67fYc9cyEzOeSjOCGC1WyfqdRtK0443gk0XGxURESnrVHREpOzJSof9izF2/Ub27tm4Zp3JeeiMLQCXJv3xbH4r1LoObBpaICIiUhap6IhI2ZadSWrkIiIW/UjtE0upYDl/psfwrIClQT/n2Oo63cHFzbycIiIiUqhUdESk3Nh6+Dg/zZhG41NL6GNbTyVL0vkH3f2hwY3Q+Bao2xNcPcwLKiIiItdMRUdEypVsu4Mf1hzm4/kRNM7awU22dQzy2IRvVsL5ndx8oH4f55meer3Bzcu8wCIiInJVVHREpFyKTUznzVk7mb09FgsObvA9zP/V2kPNuIWQdPT8jq5eENYbGt3iLD/uvuaFFhERkXxT0RGRcm1JRDyv/r6DI6fSAOjdsDJvt8+kSvTZa/WcPnx+Z5s71OvlXN5Wvy94BpgTWkRERK5IRUdEyr20TDufLd7LN8sPkO0w8HS18XTvMO7rVAvX+O3OwrPrdzi5//yTrK5Qt4dzeVuDm8Ar0Lw3ICIiIhdR0REROWtP3BlembmDdYdOAtAwyJe3B4XTumYFMAyI33W+9ByPOP9Eq4tzVHXjAdDwZvCpbNI7EBERkXNUdERELmAYBj9vPMLY2bs5lZoFwJB2NXipb0P8vS645s7xSNj1h7P0xG0/v91ihZqdnaWnUX/wDSrmdyAiIiKgoiMikqeTKZm8O2c3P204AkBFbzdeubkRA1tUx2Kx5N75xP7zZ3pitlzwgAVqdDhfevxDii2/iIhIeaeiIyJyGWsPnOCV33awN955odGOdSry70FNqVvZJ+8nnDoEu/90lp4j63M/FtLWOb2t8S1QoVaR5hYRESnvVHRERK4gM9vBtysO8OmivWRkO3CzWXmke10e614XD1fbpZ+YePR86YlaDVzwf6PBLZxnehoPgIp1i/otiIiIlDsqOiIi+RR1IpXX/tjB0sjjANSq6MVbA5tyXVg+hg+ciXWWnt1/wKG/wXCcf6xq0/Olp3KDIkovIiJSvqjoiIgUgGEYzNkRyxt/7iQuKQOAW5pX45WbG1HF1yN/L5KSABGznGd6DiwDw37+scoNzy5vGwBVm8A/vw8kIiIi+aKiIyJyFc6kZ/HRgj38b9UhHAb4erjwQt+GDG1XA5u1AOUk9SREznGWnv2LwZF1/rHAuufP9AQ3V+kREREpABUdEZFrsP1IIi//tp1tRxIBaB4awNsDm9K0un/BXyztNOyZ5yw9+xaCPeP8YwE1zpaegVC9tUqPiIjIFajoiIhcI7vDYPLaw3wwN5IzGdlYLXBf59o83bs+Pu4uV/eiGWdg73xn6dm7ALJSzz/mF+IcV914AIS2A+tlBiKIiIiUUyo6IiKFJC4pnbdm7WLWthgAgvw8eP2WxvRpEnTxtXcKIjPVeYZn1++wZy5kJp9/zMUTqjaGoGYQFO78s2pjcPO+xncjIiJSuqnoiIgUsmV7jvPqbzuIOuk8C9OzYRVev6UJoYFe1/7iWenO7/Ls+t353Z6MxDx2skDFemeLT/j5EuRb9dqPLyIiUkqo6IiIFIH0LDufL9nHV8v2k2U38HS18WSvMB7oUhtXm7VwDuKww8mDELsNYrefvW2D5Li89/euAsHNchegwDpa+iYiImWSio6ISBHaF5/MK79tZ82BkwA0qOrL24Oa0qZWYNEd9EwcxG2/oPxsh4S95Lpg6TmuXs4x1heWnyqNwa0Qzj6JiIiYSEVHRKSIGYbBr5uO8vbs3ZxMyQTgrrahvNi3IRW83YonRGYKxO8+f/YnZhvE7YTstIv3tVihYtgF5edsAfLJx4VRRURESggVHRGRYnIqJZP35kYwbX00AIHebvzfTY24rVX1axtWcLUcdjix/+KlbynH897fJyh3+QluDhVqg7WQluKJiIgUIhUdEZFituHQSV6euYPIuDMAtK8dyNuDmlKviq/Jyc46E3e+9JwrQSf2k/fSN28Iapq7AFVpDK6exR5bRETkQio6IiImyLI7+M/fB/lk4R7Ssxy42iw83LUuo66vh4drCRwOkJEM8btyn/2J2wnZ6Rfva7FCpfq5J74FhYN3peLPLSIi5ZaKjoiIiaJPpvL6HztZFBEPQI1AL94a2JRu9UvB92Hs2XBy/9nv/Gw9fxYo9UTe+/tW+8f3fsK19E1ERIqMio6IiMkMw2Dezjje+HMnMYnOMyQ3NwvmtZsbU8XPw+R0BWQYcCb2gqVvZ8/+nNyf9/5uvhcvfavcCFxL2fsWEZESR0VHRKSESM7I5pMFe5i46hB2h4GvuwvP9WnA3R1qYrOaMKygMGWcgbhdub/3E7cL7BkX72uxQeUGF0998yrCkdwiIlLmqOiIiJQwO48l8n8zd7A1+jQAzUL8eWdQOE2r+5sbrLDZs+HE3txnf2K2QdrJvPf3C8lj6VstMGNinYiIlHgqOiIiJZDdYTB1XRTvzY3gTHo2VgsM71iLZ2+oj6+Hq9nxio5hwJmY86XnXAE6dTDv/d39oOoFS9+Cm0HlhuDiXry5RUSkxFHREREpweLPpPP2X7v5fcsxAKr6ufOv/k24sWmQOdfeMUt6knPK24Vnf+J3gT3z4n2tLs7v+YS2hZB2ENoOAuvozI+ISDmjoiMiUgr8vTeBV37bzqETqQB0b1CZtwY0JTTQy+RkJrJnQcLeC4YenP0z7dTF+3pVchae0HbO8lOtJbiV49+diEg5oKIjIlJKpGfZ+XLpfr5cup9MuwMPVyuPd6/HyK51Sua1d8xgGJB0FI5ugiPrIHodHNt88Zkfq4tzqVtoewhp6/zTP0RnfUREyhAVHRGRUmb/8WRe/W0Hq/Y7r1cTUsGTl29qRN/ytpwtv7IznN/3iV57vvycibl4P9/gs2d92jvP+gQ303d9RERKMRUdEZFSyDAM/twWw9jZu3OuvdOxTkVe69+YRsH6/7/LMgxIjHYWnuh1zvITsw0Me+79bO5QrcX55W6h7cA3yJTIIiJScCo6IiKlWGpmNl8vO8BXy/aTke3AaoGh7WvwTO8GBHq7mR2v9MhMdS5xi14LR9Y7/0w9cfF+ATWcZ3zOLXmr2hRsLsWfV0RErkhFR0SkDDhyKpWxcyL4a5tzSZafhwtP967P3R1q4mqzmpyuFDIMOHng7Fmfs+Unbifwj38VunpB9da5z/rowqYiIiWCio6ISBmy9sAJ3vhzF7tikgCoV8WH125uTNf6lU1OVgakJ8HRDRB99ozPkQ2QkXjxfhXDck94q9wQrCqbIiLFTUVHRKSMsTsMftoQzQfzIjmZ4pw21qtRVV7p14halbxNTleGOByQEJn7uz4Jey7ez90fQlqfX+4W0gY8/Is/r4hIOaOiIyJSRiWmZfHpor38b9Uhsh0GrjYL93epzage9fD1cDU7XtmUevLsd3zOLnk7ugmyUv6xkwWqNMo94a1iXY22FhEpZCo6IiJl3L74ZN6atYtle44DUMnHnRf6NuD2ViFYrfpwXaTs2RC/8/xZn+i1cPrwxft5BuZe7la9Fbjp7JuIlDIZyZAcB24+4FvV7DQqOiIi5cWSiHjemrWLAwnOMwzNQvz5V/8mtK5ZweRk5cyZuPPX88m5oGlG7n0sNghqev6MT2g758Q3nfURkeKWnQHJ8WdvcZBywc/JcRf8HA9Zqc7ndHsJeowxNzcqOiIi5UpmtoPvVx9i/MK9nMnIBmBgi2q8eGNDgv09TU5XTmVnQuzZC5qeKz9njl28n08QhLa94IKmzcHVo/jzikjp57A7R+jnVVZy/jz7c/rpgr22mw+0fwR6vlok0QtCRUdEpBw6fiaDD+dHMn1DNIYBnq42Hutel5Fd6+DhajM7niQeOVt8zk54i90Gjuzc+9jcnGUntP35JW9+webkFRHzGYazlORVVv75Z2oCGI78v7bVFXyqgk+VC/6scvE27yrg7lNkb7GgVHRERMqxHUcTeePPnaw/dAqA6gGevNyvETc2DcKiZVIlR2YqxGzJXX5SEy7ez7/GBWd92kJQONg0eEKkVMtM+Udp+UdxuXApmT2zAC9sAe/KlygtFxQXnyrgWaFULp1V0RERKecMw2DWthjGzt7NscR0ADrUCeS1m5vQuJr+v7REMgw4dfCCIQfrnEMP/vlfaF08nYMNLrygqXclczKLyHnZmZBy/B9l5RJLyDKTC/baHv65y0qu0nLBNq+KYHMpmvdXQqjoiIgIAGmZdr5atp+vlu0nI9uB1QJD2tXg2RsaEOjtZnY8uZKMM3B0Y+7r+qTncUFTNx/nBxzvSs7/mutVCbwrnv2z0j/uVwY3r+J/LyKlkcMBaSfz972XtJMFe20XT+cUM5+qZ8/C/LPInCszlfXdvQuo6IiISC5HT6cxdvZuZm2LAcDPw4WnetXnno41cbVZTU4n+eZwOC9gemTd+SVvCZEFfx1XrzzKUEXnB6qcYlTpfHly8ymVS1ykHHA4nEu7stPP/5l97n7GBT/n87H0xNylJuU4GPb857G6nF8adlFp+UeZ0T9XV0VFR0RE8rTu4Ene+HMnO48lAVC3sjev9W9Ct/qVTU4mVy3jzNkPZAnO7/ikHD/784kLtl1w/59jr/PD5n72bFGlS5wlOncm6WwxcvfTB7iyzp59tiycu/2jMNgz/lEs8vlYzv08XjOv1ynQ91eulsX5dztXcbnEGRiPALDqPx4VJRUdERG5JLvD4OcN0XwwL5ITKc4PCb0aVeHlfo2pXUkXtCzTDMNZjFITIOXEBSXoH2Uo5fj5n7PTCn4cm5vzg+E/l8xdtJzu7FkjfTgsGMO44AN/BmSlnS0GaXnfz06HrPSz+6eff94lC8oFtzxLSUbBznIUJxcPZzF3ueB24X2bm3MfF7e893XzAd+g3MvJvCtpAEgJoqIjIiJXlJiWxWeL9jJp1SGyHQauNgv3d67NqOvr4euhf6nLWZkpF5ShE1c+a1TQL1mD82KqeZ0lOnc/53tHZ7d5VigZxcgwzheHfxaJvIrFlQpJ1gXF5EqvSwn6CGexni0P50rFJUrEZQvI5fb1yKOguF38mM1VZxLLARUdERHJt/3Hk/n3rF0siTwOQCUfN17o05DbW4dgtepDgxRQVtrZAnQ8f2eNMpIKfgyLFTwDc58Zyuu7Ra7eZwvCZc5sXPL+5QpJ+vnveZQELh4X3NzB1fNsCfD8x/1/7JerVPyzRJy9f8nHLnhuGZ/yJSWLio6IiBTYkoh43pq1iwMJKQCEV/fnX/0b06ZWoMnJpEzLzvjHmaErnDUq6BXdi4vF6iwWrh5XVzyu9nku7jqLIeVKkRSdsWPH8uuvvxIREYGnpyedOnXivffeo0GDBpd8zqRJk7jvvvtybXN3dyc9PT2/h1XREREpRpnZDr5ffYjxC/dyJiMbgFuaV2PMTQ0J9vc0OZ0IYM+C1JP5G7yQlXa2QFxtqfC4RNG4oHCcey19h0OkWOS3GxToPOOyZct4/PHHadu2LdnZ2fzf//0fN9xwA7t27cLb+9JfXvXz8yMy8vzoS12VW0Sk5HJzsfLgdXUY2LI6H86PZNr6aP7YeowFu+J4tHtdHupaBw9Xm9kxpTyzuTqvPeJb1ewkIlKCXdPStePHj1OlShWWLVtG165d89xn0qRJPPXUU5w+ffpqD6MzOiIiJtpxNJE3/9zFukPOC+FVD/Dk/25qxE3hQfoPVyIiUuzy2w2uaVxJYqLzysyBgZdfu52cnEzNmjUJDQ1lwIAB7Ny587L7Z2RkkJSUlOsmIiLmaFrdn+kPd2DC0JZU8/fg6Ok0Hp+yicHfrGHnsUSz44mIiOTpqs/oOBwObrnlFk6fPs3ff/99yf1Wr17N3r17adasGYmJiYwbN47ly5ezc+dOQkJC8nzO66+/zhtvvHHRdp3RERExV1qmnW+WH+DLZftIz3JgtcBd7WrwbO/6VPRxNzueiIiUA0U+de3RRx9lzpw5/P3335csLHnJysqiUaNGDBkyhLfeeivPfTIyMsjIOD+uMSkpidDQUBUdEZES4ujpNN6dE8GfW48B4OvhwlO96jO8Y01cbSXg2iYiIlJmFenStVGjRjFr1iyWLFlSoJID4OrqSsuWLdm3b98l93F3d8fPzy/XTURESo7qAZ58NqQlPz/SkSbV/DiTns1bs3bR95PlLI2MNzueiIhIwYqOYRiMGjWKmTNnsnjxYmrXrl3gA9rtdrZv305wcHCBnysiIiVL21qB/DGqC+/dFk4lHzf2H09hxMT13D9pPQeOJ5sdT0REyrECFZ3HH3+cH3/8kSlTpuDr60tsbCyxsbGkpaXl7DN8+HDGjBmTc//NN99k/vz5HDhwgE2bNnH33Xdz+PBhHnzwwcJ7FyIiYhqb1cLgtjVY/Fx3HupaB1ebhcUR8fT5ZDnvzN5NUnqW2RFFRKQcKlDR+fLLL0lMTKR79+4EBwfn3KZPn56zT1RUFDExMTn3T506xciRI2nUqBE33XQTSUlJrFq1isaNGxfeuxAREdP5ebjyfzc1Yt5TXbm+YRWy7AbfLD/A9eOWMn19FHbHVV/NQEREpMCu6To6xUXX0RERKX2WRMbz1qxdHDieAkDT6n78q38T2ta6/CUJRERELqfIp64VJxUdEZHSKcvu4PvVh/lk4R7OpGcD0L95Ncbc2JBqAZ4mpxMRkdJIRUdEREqME8kZjJu/h2nrozAM8HC18mi3ejzUtQ6ebjaz44mISCmioiMiIiXOzmOJvPHnLtYdPAk4x1SPuakh/cKDsVgsJqcTEZHSQEVHRERKJMMwmL09lndm7+boaefUzna1Anmtf2OaVvc3OZ2IiJR0KjoiIlKipWfZ+Wb5Ab5Yuo/0LAcWC9zVNpTnbmhARR93s+OJiEgJpaIjIiKlwrHTabw7J4I/th4DwNfDhSd7hjG8Yy3cXAp0FQQRESkHVHRERKRUWX/oJG/8uZMdR5MAqFPZm1dvbkyPBlVMTiYiIiWJio6IiJQ6DofBjI1HeH9eBAnJmQD0aFCZV25uTN3KPianExGRkkBFR0RESq0z6Vl8tngfE1ceJMtu4GK1MKJTLUb3CsPPw9XseCIiYiIVHRERKfUOHE/m7b92sygiHoCK3m6M7hnGkHY19P0dEZFySkVHRETKjKWR8bw1axf7j6cAULOiF8/d0ICbm+n6OyIi5Y2KjoiIlClZdgfT10fzycK9JCRnANAsxJ+XbmxIp7qVTE4nIiLFRUVHRETKpJSMbP7z90G+XraflEw7AN3qV+alGxvSKFj/jhARKetUdEREpExLSM7gs0V7mbw2imyHgcUCg1pW59kbGlA9wNPseCIiUkRUdEREpFw4lJDCuPmRzNoWA4Cbi5V7O9bk8R71CPByMzmdiIgUNhUdEREpV7ZGn+bdORGsPnACAD8PFx7rUY8RnWrh4WozOZ2IiBQWFR0RESl3DMNg2Z7jvDsngojYMwAE+3vwdO/63NYqBJtVE9pEREo7FR0RESm37A6D3zYf5aMFezh6Og2ABlV9efHGBvRoUEUjqUVESjEVHRERKffSs+z8sPowE5bsIzEtC4B2tQMZc2NDWtaoYHI6ERG5Gio6IiIiZyWmZvHFsn1MXHmIzGwHADc2DeL5Pg2oU9nH5HQiIlIQKjoiIiL/cOx0Gh8v2MMvm47gMMBmtTCkXSije4ZRxdfD7HgiIpIPKjoiIiKXEBl7hvfnRrAoIh4ALzcbD15Xh4e61sHH3cXkdCIicjkqOiIiIlew5sAJ3p0TwZbo0wBU8nFjdM8w7mpbAzcXq7nhREQkTyo6IiIi+WAYBnN3xPL+vEgOJqQAULOiF8/3aUC/8GBNaBMRKWFUdERERAogy+5g2vpoxi/cS0JyBgDNQ/x58caGdKpbyeR0IiJyjoqOiIjIVUjJyOa7FQf5Zvl+UjLtAHRvUJkX+zakUbD+HSQiYjYVHRERkWtw/EwGny3ey5S1UWQ7DCwWGNSyOs/e0IDqAZ5mxxMRKbdUdERERArBoYQUPpgfyV/bYgBwc7EyolMtHutelwAvN5PTiYiUPyo6IiIihWhr9GnGztnNmgMnAfDzcOGxHvUY0akWHq42k9OJiJQfKjoiIiKFzDAMlu45zntzIoiIPQNAsL8HT/euz22tQrBZNaFNRKSoqeiIiIgUEbvD4LfNR/lwfiTHEtMBaFDVlxdvbECPBlU0klpEpAip6IiIiBSx9Cw7368+xOdL9pOYlgVA+9qBvHRjQ1rWqGByOhGRsklFR0REpJgkpmbxxbJ9TFx5iMxsBwA3hQfxfJ+G1K7kbXI6EZGyRUVHRESkmB07ncZHC/bwy6YjGAa4WC3c1S6UJ3vWp7Kvu9nxRETKBBUdERERk0TEJvH+3EgWR8QD4OVm48Hr6vBQ1zr4uLuYnE5EpHRT0RERETHZmgMnGDsngq3RpwGo5OPG6J5hDGlXA1eb1dxwIiKllIqOiIhICWAYBnN2xPLBvEgOJqQAUKuiF8/1aUC/8GBNaBMRKSAVHRERkRIky+5g2rooxi/aS0JyJgDNQ/x56cZGdKxb0eR0IiKlh4qOiIhICZSSkc23Kw7wzfIDpGbaAejeoDIv9m1Io2D9O05E5EpUdEREREqw42cy+HTRXqauiyLbYWCxwK0tQ3jmhvpUD/A0O56ISImloiMiIlIKHExIYdy8SP7aHgOAm4uVEZ1q8Vj3ugR4uZmcTkSk5FHRERERKUW2RJ9m7OzdrD14EgA/Dxce61GPEZ1q4eFqMzmdiEjJoaIjIiJSyhiGwdLI47w7J4LIuDMAVPP34One9bm1VQg2qya0iYio6IiIiJRSdofBzM1H+Wh+JMcS0wFoUNWXF29sQI8GVTSSWkTKNRUdERGRUi49y87/Vh3i8yX7SErPBqB97UBeurEhLWtUMDmdiIg5VHRERETKiMTULL5Yuo+Jqw6Rme0A4KbwIJ7v05DalbxNTiciUrxUdERERMqYo6fT+HjBHn7ZdATDABerhbvahfJkz/pU9nU3O56ISLFQ0RERESmjImKTeG9OBEsijwPg5WbjwevqMPK62vh6uJqcTkSkaKnoiIiIlHGr95/g3Tm72XokEYBAbzdG9ajHsA41cHfRSGoRKZtUdERERMoBwzCYvT2WcfMjOZiQAkBIBU+e6V2fAS2qayS1iJQ5KjoiIiLlSJbdwU8bohm/cC/xZzIAaBjkywt9NZJaRMoWFR0REZFyKC3TzsRVB/ly6X7OnB1J3a5WIC/e2JDWNTWSWkRKPxUdERGRcux0aiZfLt2fayR178ZVeaFPA8Kq+pqcTkTk6qnoiIiICDGJaXyyYC8/b4zGYYDVAre1CuHp3vWpFuBpdjwRkQJT0REREZEc++LP8MG8SObtjAPAzcXKvR1r8lj3elTwdjM5nYhI/qnoiIiIyEU2RZ3ivTkRrD14EgBfdxce7laH+7vUxsvNxeR0IiJXpqIjIiIieTIMg6V7jvP+3Eh2xyQBUNnXndE9w7irbSiuNqvJCUVELk1FR0RERC7L4TD4Y+sxPlwQSfTJNABqVfTi2Rsa0C88GKuuwSMiJZCKjoiIiORLZraDKWsP89nifZxIyQQgvLo/L/RtwHVhlU1OJyKSm4qOiIiIFEhyRjbfrTjAt8sPkJJpB6BzvYq82LchzUICzA0nInKWio6IiIhclYTkDCYs3sfktYfJsjs/JvQLD+bZG+pTp7KPyelEpLxT0REREZFrEn0ylY8X7GHmlqMYBtisFga3DeWpnmFU8fMwO56IlFMqOiIiIlIodsck8cG8SBZHxAPg4Wrl/s61ebhbXfw9XU1OJyLljYqOiIiIFKp1B0/y7pzdbIo6DYC/pyuP96jL8I618HC1mRtORMoNFR0REREpdIZhsGBXHB/Mi2RvfDIAwf4ePN2rPre2qo6LrsEjIkVMRUdERESKjN1h8MumI3yyYA/HEtMBqFfFh+duaECfJlWxWHQNHhEpGio6IiIiUuTSs+z8sPowny/dx+nULABa1gjgxb4N6VCnosnpRKQsUtERERGRYpOUnsXXy/bzn78Pkp7lAKB7g8q80Kchjavp390iUnhUdERERKTYxSelM37RXqatj8buMLBYYEDzajx7QwNCA73MjiciZYCKjoiIiJjmYEIK4+ZH8te2GABcbRaGta/JqOvrUcnH3eR0IlKaqeiIiIiI6bYfSeT9eRGs2JsAgLebjQevq8PIrnXwcXcxOZ2IlEYqOiIiIlJi/L03gffmRrD9aCIAFb3dGHV9PYa2r4G7i67BIyL5p6IjIiIiJYrDYTBnRyzj5kdyMCEFgJAKnjx7Q30GNK+O1aqR1CJyZSo6IiIiUiJl2R38tCGa8Qv3En8mA4CGQb682Lch3RtU1jV4ROSyVHRERESkREvLtPPflQf5atl+zqRnA9CudiAv3diQVjUqmJxOREoqFR0REREpFU6lZPLlsv1MWnWIzGznNXhuaFyVF/o2oF4VX5PTiUhJo6IjIiIipcqx02l8snAPMzYewWGA1QK3tw7hqV71qRbgaXY8ESkhVHRERESkVNobd4YP5kUyf1ccAG4uVkZ0qsWj3epSwdvN5HQiYjYVHRERESnVNh4+xXtzI1h38CQAvh4uPNKtLvd1roWXm67BI1JeqeiIiIhIqWcYBksjj/Pe3AgiYs8AUNnXnSd7hjG4bSiuNqvJCUWkuKnoiIiISJnhcBj8vvUoH87fw5FTaQDUruTNszfU56amwboGj0g5oqIjIiIiZU5Gtp2pa6P4bPE+TqRkAhBe3Z8X+zakS1glk9OJSHFQ0REREZEyKzkjm+9WHODb5QdIybQD0KVeJV7s25DwEH+T04lIUVLRERERkTIvITmDCYv3MXntYbLszo80/ZoF89wNDahdydvkdCJSFFR0REREpNyIPpnKRwv28NuWoxgGuFgtDG4bypM9w6ji52F2PBEpRCo6IiIiUu7sjkni/bkRLIk8DoCHq5XhHWvxcNc6VPRxNzmdiBQGFR0REREpt9YeOMF7cyPYFHUaAC83G/d2qsVD19XRRUdFSjkVHRERESnXzl2D5+OFe9h2JBEAbzcb93WuzYPX1SbAS4VHpDRS0RERERHBWXgW7Y7nowV72BWTBICvuwv3d6nN/V1q4+/panJCESkIFR0RERGRCxiGwbydcXyycA8RsWcA8PNwYeR1dRjRuRa+Hio8IqWBio6IiIhIHhwOgzk7Yvlk4R72xicDEODlykNd63Bvx1p4u7uYnFBELkdFR0REROQy7A6Dv7bH8MnCPRw4ngJAoLcbD3etwz0da+LlpsIjUhKp6IiIiIjkg91h8MfWo4xfuJdDJ1IBqOTjxiPd6nJ3h5p4uNpMTigiF1LRERERESmAbLuDmZuP8univUSfTAOgiq87j3Wvy13taqjwiJQQKjoiIiIiVyHL7uCXjUf4bPE+jp52Fp4gPw8ev74ed7YJwd1FhUfETPntBtaCvOjYsWNp27Ytvr6+VKlShYEDBxIZGXnF5/388880bNgQDw8PwsPDmT17dkEOKyIiIlJsXG1W7mpXgyXPdeffA5sS7O9BbFI6r/62g+vHLWPquiiy7A6zY4rIFRSo6CxbtozHH3+cNWvWsGDBArKysrjhhhtISUm55HNWrVrFkCFDeOCBB9i8eTMDBw5k4MCB7Nix45rDi4iIiBQVNxcrd3eoydLnu/PmgCZU9XPn6Ok0xvy6nR7jlvLT+mgVHpES7JqWrh0/fpwqVaqwbNkyunbtmuc+gwcPJiUlhVmzZuVs69ChAy1atOCrr77K13G0dE1ERETMlp5lZ8raKL5Yup+E5AwAalb0YvT1YQxoUQ0XW4H++7GIXKUiWbr2T4mJiQAEBgZecp/Vq1fTq1evXNv69OnD6tWrL/mcjIwMkpKSct1EREREzOThauP+LrVZ8UIPXr6pERW93Th8IpVnf97KDR8v5/ctR7E7SvxXn0XKjasuOg6Hg6eeeorOnTvTtGnTS+4XGxtL1apVc22rWrUqsbGxl3zO2LFj8ff3z7mFhoZebUwRERGRQuXpZmNk1zqseLEHL93YkAperhxISOHJaVvo88lyZm07hkOFR8R0V110Hn/8cXbs2MG0adMKMw8AY8aMITExMecWHR1d6McQERERuRZebi480q0uK168nuf7NMDf05V98cmMmrKZG8evYM72GBUeERNd1SV/R40axaxZs1i+fDkhISGX3TcoKIi4uLhc2+Li4ggKCrrkc9zd3XF3d7+aaCIiIiLFysfdhcd71OOejjWZ+Pchvvv7AJFxZ3h08iYaBfvxdK8wejeuisViMTuqSLlSoDM6hmEwatQoZs6cyeLFi6ldu/YVn9OxY0cWLVqUa9uCBQvo2LFjwZKKiIiIlGB+Hq482SuMv1+4ntHX18PH3YXdMUk89MNGbpmwksURcZSCyxeKlBkFmrr22GOPMWXKFH7//XcaNGiQs93f3x9PT08Ahg8fTvXq1Rk7dizgHC/drVs33n33Xfr168e0adN455132LRp02W/23MhTV0TERGR0uZUSibf/X2AiSsPkZppB6B5aABP9wqjW/3KOsMjcpXy2w0KVHQu9Q/kxIkTGTFiBADdu3enVq1aTJo0Kefxn3/+mVdeeYVDhw4RFhbG+++/z0033ZTfw6roiIiISKl1IjmDb1Yc4PtVh0nLchaeVjUCeKZ3AzrXq6jCI1JARVJ0zKKiIyIiIqXd8TMZfL1sPz+sOUxGtvNCo+1qBfJ07/p0rFvR5HQipYeKjoiIiEgJFJ+UzhdL9zNlXRSZZwtPxzoVeeaG+rStdelrE4qIk4qOiIiISAkWm5jOF0v3MXVdFFl258ex68Iq8VSv+rSuWcHkdCIll4qOiIiISClw9HQany/Zx0/ro8k+e92dbvUr83Tv+rQIDTA3nEgJpKIjIiIiUopEn0xlwuJ9zNh0BPvZwtOzYRWe7l2fptX9TU4nUnKo6IiIiIiUQodPpPDpon3M3HyEs32HGxpX5ale9WlcTZ+DRFR0REREREqxA8eT+WzxPn7bcpRzn9ZuCg/iyZ71aRDka244EROp6IiIiIiUAfvizzB+0T5mbTuGYYDFAjc3q8aTPetRr4oKj5Q/KjoiIiIiZUhk7BnGL9rD7O2xgLPwDGhejdE9w6hT2cfkdCLFR0VHREREpAzadSyJTxbuYf6uOACsFhjUMoTRPetRs6K3yelEip6KjoiIiEgZtuNoIp8s3MPC3fEA2KwWbm8Vwqjr6xEa6GVyOpGio6IjIiIiUg5siT7NJwv3sDTyOAAuVgt3tg3l8R71qB7gaXI6kcKnoiMiIiJSjmw8fIpPFu5hxd4EANxsVgafLTxB/h4mpxMpPCo6IiIiIuXQ+kMn+XjBHlbtPwGAm4uVoe1q8Fj3ulTxU+GR0k9FR0RERKQcW73/BB8v2MO6QycBcHexck+HmjzcrS6Vfd1NTidy9VR0RERERMo5wzBYtf8EH86PZFPUaQA8XW0M71iTh7rWoaKPCo+UPio6IiIiIgI4C8/yvQl8tGAPW6NPA+DhamVYe2fhqaolbVKKqOiIiIiISC6GYbAkMp5PFu5l25FEwDm04I42ITzSra7GUkupoKIjIiIiInkyDIMVexP4bPFe1h86BTjHUg9sWZ3HutelTmUfkxOKXJqKjoiIiIhc0doDJ5iwZF/OWGqLBfqFBzPq+no0DNLnLil5VHREREREJN+2RJ9mwuJ9LNwdl7Otd+OqjOpRj+ahAeYFE/kHFR0RERERKbBdx5L4fOk+Zm+P4dynxK71K/PE9fVoWyvQ3HAiqOiIiIiIyDXYF5/MF0v38fuWY9gdzo+L7WsH8sT1YXSuVxGLxWJyQimvVHRERERE5JpFnUjlq+X7+XlDNFl258fGFqEBjOpRj56NqqjwSLFT0RERERGRQhOTmMY3yw8wZW0UGdkOABoF+zGqRz36Ng3CZlXhkeKhoiMiIiIihe74mQz+8/dBflh9iJRMOwB1K3vzeI963NK8Gi42q8kJpaxT0RERERGRInM6NZOJKw8xceVBktKzAQgN9OTRbvW4rXV13F1sJieUskpFR0RERESK3Jn0LH5cE8V3Kw5wIiUTgCA/Dx7uVoe72tbA002FRwqXio6IiIiIFJu0TDtT10Xx9fL9xCVlAFDJx40Hr6vD3R1q4uPuYnJCKStUdERERESk2GVk25mx8QhfLt3PkVNpAPh7unJf51rc16k2/l6uJieU0k5FR0RERERMk2V38MeWY3y+dB8HjqcA4OPuwj0da/JAl9pU8nE3OaGUVio6IiIiImI6u8Ngzo4YJizeR0TsGQA8XK0MbVeTh7rWIcjfw+SEUtqo6IiIiIhIieFwGCyKiGfC4r1sPZIIgJvNyu1tQni0W11CA71MTiilhYqOiIiIiJQ4hmHw974EPlu8j3UHTwJgs1oY2KI6j/WoS93KPiYnlJJORUdERERESrS1B04wYck+VuxNAMBigX7hwTzeox6NgvWZT/KmoiMiIiIipcKW6NNMWPz/7d1pcBTngcbxZ2YkjQ6EQICOQRoYSSTY3CCEARvEERNisybljZcUeLVmE29AOGDs1CpJEX+IbWxXJUUZhDDYMeuD2N6lIHay2TUGIRDmVkRMcXmQQEIgCYzR6EAHM70fWFShArYGA90z+v+q+sO8rdY8Kr0lvU/1dLdXnxyt6xybfk+yFk3N0sj0XuYFgyVRdAAAABBSjp7zqbDYqz99dk7XVqgPDOqrp6YOUo4n0dxwsAyKDgAAAEKSt75JRdtPanN5jfyBq0vVHE+inpqapfuz+spms5mcEGai6AAAACCkVV9sUVHJSf3XgTNq9wckSSPSe2nRlCxNvyeJwtNNUXQAAAAQFmobWrV2R4U27Dut1o6rhWdwSrwWTc3SzKGpctgpPN0JRQcAAABh5UJTm94ordRbn55Sc7tfkpTRL075uVn6h5EuRTrsJifE3UDRAQAAQFi61NKu9Z+e0pu7TqnhcockKa13jBbkZuofx6TJGeEwOSHuJIoOAAAAwlpja4fe2VOlN0ordKGpXZKU0jNaT07K0A9z3IqJovCEI4oOAAAAuoXL7X69t79Kr5VUqNbXKknqExelHz2QoXn3uRUfHWlyQtxOFB0AAAB0K21X/Np4sEZFJV5VX7wsSUqIidS/TBioJyYOVK/YKJMT4nag6AAAAKBbuuIP6MNDZ7Wq2KuK882SpLgohx4fP1A/esCjvj2cJifEN0HRAQAAQLfmDxj6n8O1Wrntcx2rbZQkRUfa9cMct56clKHUhBiTE+JWUHQAAAAASYZhaOvReq0s9upQ9SVJUpTDrkfHpGnB5Ey5+8SaGxBBoegAAAAAf8MwDJV6L2jlNq/2VV6UJDnsNj0y0qWFuVnKSuphckJ0BUUHAAAAuIl9lRe1qtirHSfOS5JsNul7w1KVn5ule12sN62MogMAAAB8jUPVl7Sq2KstR+o6x6YOTlL+lEyNGZBoYjLcDEUHAAAA6KJjtT6t2ubVnz47p2ur43GeROVPydIDg/rKZrOZGxCdKDoAAABAkCovNOu1kpPaWHZGHf6ry+Rh/ROUPyVTD96bIrudwmM2ig4AAABwi841XNa6HZX6/b4qXe7wS5Iy+8VpQW6WHhnpUqTDbnLC7ouiAwAAAHxDF5vbtX5XpdZ/ekq+1iuSpP69YvTkpAz909h0RUc6TE7Y/VB0AAAAgNuksbVD7+6t0us7K3WhqU2S1LdHlObf79G8+waoZ3SkyQm7D4oOAAAAcJu1dvj1nweqtaakQjWXLkuS4qMjlDd+oJ6YOFB9ejhNThj+KDoAAADAHdLhD+ijQ2e1evtJeeubJEnRkXbNGevWk5My5OoVY3LC8EXRAQAAAO6wQMDQx0fqtHq7V3890yBJinTY9P1R/fWTyZnK6NfD5IThh6IDAAAA3CWGYajUe0Gri09qd8UXkiSbTfre0FQtyM3U0P4JJicMHxQdAAAAwAQHT3+pou1efXK0vnMs99v9lD8lS2MHJpqYLDxQdAAAAAATHav1qWj7SX106KwC/7/izhmYqIVTMjX5W/1ks/Hw0VtB0QEAAAAs4PQXzVpTUqGNB8+o3R+QJA1x9dTC3Cx9d2iKHHYKTzAoOgAAAICF1Pla9frOCr27t0ot7X5JUkbfOP0kN1OzR/ZXVITd5IShgaIDAAAAWNCXze1a/+kprf/0lBoud0iSXAnR+vGkDM0Z61ZMlMPkhNZG0QEAAAAsrKntijbsPa11Oyt1vrFNktQnLkrz7/do3n0DlBATaXJCa6LoAAAAACGgtcOvjWVntKbkpKovXpYkxTsjNG/8AM2f6FG/eKfJCa2FogMAAACEkCv+gP702TkVFnt1oq5JkuSMsGvO2HT9eFKG0nrHmpzQGig6AAAAQAgKBAxtPVavVcVeHaq+JEmKsNv0yMj+WpCbqaykHuYGNBlFBwAAAAhhhmFo98kvVLjdq13eLyRJNpv03SEpWpibpWFpCSYnNAdFBwAAAAgT5dWXtLrYq4+P1HWOTfpWP+XnZirHk9itHj5K0QEAAADCzIm6RhVtP6kPD52VP3B1GT9mQG/lT8nUlG8ndYvCQ9EBAAAAwlT1xRa9tuOkPjhwRu1XApKke1J7amFupr43LFUOe/gWHooOAAAAEObqfa16o7RS7+w5reZ2vyRpYJ9Y/WRypr4/ur+cEeH38FGKDgAAANBNNLR06D92n9LvdlXqUkuHJCmlZ7R+PClDP8xJV2xUhMkJbx+KDgAAANDNNLdd0e/3VWndzgrV+dokSb1jIzV/okf/PH6gEmIjTU74zVF0AAAAgG6q7Ypfm8pqVFRyUqe/aJEk9XBGaO59bv3r/R4lxUebnPDWUXQAAACAbu6KP6D/Plyr1cVeHattlCRFRdj1WHaa/m1SptITY01OGDyKDgAAAABJVx8+uu1YvQqLvSqruiRJcthtemSESwtyMzUoOd7cgEGg6AAAAAC4jmEY2lt5UYXFXu38/ELn+IwhyVqYm6UR6b3MC9dFFB0AAAAAN/XXM5e0uvik/vdIra41gvuz+mrhlEyNz+hj2YePUnQAAAAAfC1vfaOKtldoc3mN/IGr1WCUu5fyc7M0dXCS7BZ7+ChFBwAAAECXVV9s0bqdFXp/f7XargQkSYNT4rUgN1MPDUtVhMNucsKrKDoAAAAAgna+sU2/21Wpt3efVlPbFUmSOzFWi6cN0qNj0kxO1/VuYI1aBgAAAMAS+sU79e/fHaxdBVP17IPfUmJclKoutuhEXaPZ0YLCGR0AAAAAN9XSfkXv7avWw8NTldTT/AeNdrUbRNzFTAAAAABCTGxUhObf7zE7RtD46BoAAACAsEPRAQAAABB2KDoAAAAAwg5FBwAAAEDYoegAAAAACDsUHQAAAABhh6IDAAAAIOxQdAAAAACEHYoOAAAAgLBD0QEAAAAQdoIuOjt27NCsWbPkcrlks9m0efPmr/z67du3y2az/d1WW1t7q5kBAAAA4CsFXXSam5s1YsQIFRYWBnXc8ePHde7cuc4tKSkp2LcGAAAAgC6JCPaAmTNnaubMmUG/UVJSknr16hX0cQAAAAAQrLt2jc7IkSOVmpqq73znO9q1a9dXfm1bW5t8Pt91GwAAAAB01R0vOqmpqVqzZo02btyojRs3Kj09Xbm5uSorK7vpMcuXL1dCQkLnlp6efqdjAgAAAAgjNsMwjFs+2GbTpk2bNHv27KCOmzx5stxut95+++0b7m9ra1NbW1vna5/Pp/T0dDU0NKhnz563GhcAAABAiPP5fEpISPjabhD0NTq3Q05OjkpLS2+63+l0yul03sVEAAAAAMKJKc/RKS8vV2pqqhlvDQAAAKAbCPqMTlNTk7xeb+fryspKlZeXKzExUW63Wz//+c9VU1Ojt956S5K0YsUKeTweDRkyRK2trXr99de1bds2ffzxx7fvpwAAAACAvxF00Tlw4ICmTJnS+Xrp0qWSpLy8PK1fv17nzp1TVVVV5/729nY988wzqqmpUWxsrIYPH65PPvnkuu8BAAAAALfTN7oZwd3S1QuOAAAAAIS3rnYDU67RAQAAAIA7iaIDAAAAIOxQdAAAAACEHVOeoxOsa5cR+Xw+k5MAAAAAMNO1TvB1txoIiaLT2NgoSUpPTzc5CQAAAAAraGxsVEJCwk33h8Rd1wKBgM6ePav4+HjZbDZTs/h8PqWnp6u6upo7wKFLmDMIFnMGwWLOIFjMGQTDavPFMAw1NjbK5XLJbr/5lTghcUbHbrcrLS3N7BjX6dmzpyV+0QgdzBkEizmDYDFnECzmDIJhpfnyVWdyruFmBAAAAADCDkUHAAAAQNih6ATJ6XTqueeek9PpNDsKQgRzBsFiziBYzBkEizmDYITqfAmJmxEAAAAAQDA4owMAAAAg7FB0AAAAAIQdig4AAACAsEPRAQAAABB2KDpBKCws1MCBAxUdHa1x48Zp3759ZkeCRS1fvlxjx45VfHy8kpKSNHv2bB0/ftzsWAghL730kmw2m5YsWWJ2FFhYTU2N5s2bpz59+igmJkbDhg3TgQMHzI4Fi/L7/Vq2bJk8Ho9iYmKUmZmpX//61+K+VLhmx44dmjVrllwul2w2mzZv3nzdfsMw9Ktf/UqpqamKiYnR9OnT9fnnn5sTtgsoOl30/vvva+nSpXruuedUVlamESNGaMaMGaqvrzc7GiyopKRE+fn52rNnj7Zs2aKOjg49+OCDam5uNjsaQsD+/fv12muvafjw4WZHgYV9+eWXmjhxoiIjI/XnP/9ZR44c0W9+8xv17t3b7GiwqJdffllFRUVatWqVjh49qpdfflmvvPKKVq5caXY0WERzc7NGjBihwsLCG+5/5ZVX9Oqrr2rNmjXau3ev4uLiNGPGDLW2tt7lpF3D7aW7aNy4cRo7dqxWrVolSQoEAkpPT9dTTz2lgoICk9PB6s6fP6+kpCSVlJRo0qRJZseBhTU1NWn06NFavXq1nn/+eY0cOVIrVqwwOxYsqKCgQLt27dLOnTvNjoIQ8fDDDys5OVlvvPFG59ijjz6qmJgYvfPOOyYmgxXZbDZt2rRJs2fPlnT1bI7L5dIzzzyjZ599VpLU0NCg5ORkrV+/XnPmzDEx7Y1xRqcL2tvbdfDgQU2fPr1zzG63a/r06dq9e7eJyRAqGhoaJEmJiYkmJ4HV5efn66GHHrru7w1wIx9++KGys7P1gx/8QElJSRo1apTWrVtndixY2IQJE7R161adOHFCknTo0CGVlpZq5syZJidDKKisrFRtbe11/58SEhI0btw4y66HI8wOEAouXLggv9+v5OTk68aTk5N17Ngxk1IhVAQCAS1ZskQTJ07U0KFDzY4DC3vvvfdUVlam/fv3mx0FIaCiokJFRUVaunSpfvGLX2j//v366U9/qqioKOXl5ZkdDxZUUFAgn8+nwYMHy+FwyO/364UXXtDcuXPNjoYQUFtbK0k3XA9f22c1FB3gDsvPz9fhw4dVWlpqdhRYWHV1tRYvXqwtW7YoOjra7DgIAYFAQNnZ2XrxxRclSaNGjdLhw4e1Zs0aig5u6IMPPtC7776rDRs2aMiQISovL9eSJUvkcrmYMwhLfHStC/r27SuHw6G6urrrxuvq6pSSkmJSKoSCRYsW6Y9//KOKi4uVlpZmdhxY2MGDB1VfX6/Ro0crIiJCERERKikp0auvvqqIiAj5/X6zI8JiUlNTde+99143ds8996iqqsqkRLC6n/3sZyooKNCcOXM0bNgwPf7443r66ae1fPlys6MhBFxb84bSepii0wVRUVEaM2aMtm7d2jkWCAS0detWjR8/3sRksCrDMLRo0SJt2rRJ27Ztk8fjMTsSLG7atGn67LPPVF5e3rllZ2dr7ty5Ki8vl8PhMDsiLGbixIl/d9v6EydOaMCAASYlgtW1tLTIbr9+6edwOBQIBExKhFDi8XiUkpJy3XrY5/Np7969ll0P89G1Llq6dKny8vKUnZ2tnJwcrVixQs3NzXriiSfMjgYLys/P14YNG/SHP/xB8fHxnZ9dTUhIUExMjMnpYEXx8fF/dw1XXFyc+vTpw7VduKGnn35aEyZM0IsvvqjHHntM+/bt09q1a7V27Vqzo8GiZs2apRdeeEFut1tDhgzRX/7yF/32t7/V/PnzzY4Gi2hqapLX6+18XVlZqfLyciUmJsrtdmvJkiV6/vnnNWjQIHk8Hi1btkwul6vzzmyWY6DLVq5cabjdbiMqKsrIyckx9uzZY3YkWJSkG25vvvmm2dEQQiZPnmwsXrzY7BiwsI8++sgYOnSo4XQ6jcGDBxtr1641OxIszOfzGYsXLzbcbrcRHR1tZGRkGL/85S+NtrY2s6PBIoqLi2+4fsnLyzMMwzACgYCxbNkyIzk52XA6nca0adOM48ePmxv6K/AcHQAAAABhh2t0AAAAAIQdig4AAACAsEPRAQAAABB2KDoAAAAAwg5FBwAAAEDYoegAAAAACDsUHQAAAABhh6IDAAAAIOxQdAAAAACEHYoOAAAAgLBD0QEAAAAQdig6AAAAAMLO/wHPiPaWXKFe7AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "artifacts_path = f'{drive_model_location}/additive-attention-de-en-translator-basic-model-artifacts.json'\n",
        "save_artifacts(basic_model, train_losses, val_losses, artifacts_path, model_path)\n",
        "show_graph(train_losses, val_losses, save_path=f'{drive_model_location}/additive-attention-de-en-translator-basic-model-loss-graph.png', save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "6982be21",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model(model, model_path):\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "50f141b1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5422, 512, padding_idx=0)\n",
              "    (lstm): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
              "    (hidden_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (cell_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(4560, 512, padding_idx=0)\n",
              "    (lstm): LSTM(512, 512, num_layers=2, batch_first=True)\n",
              "    (encoder_hidden_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (encoder_cell_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (output_projection): Linear(in_features=512, out_features=4560, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_model(basic_model, 'weights/additive-attention-de-en-translator-basic-model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "e3e692ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = load_dataset(\"bentrevett/multi30k\", split=\"test\")\n",
        "test_dataset = test_dataset.map(\n",
        "    lambda x: preprocess(x, \"de\", \"en\", de_vocab_to_index, en_vocab_to_index),\n",
        "    batched=True,\n",
        "    remove_columns=[\"en\", \"de\"]\n",
        ")\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"source\", \"target\"])\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "id": "a5e0bc26",
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def translate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    one_batch = next(iter(test_loader))\n",
        "    one_batch = batch_to_device(one_batch, device)\n",
        "\n",
        "    targets = one_batch[\"target\"]\n",
        "    logits_all, preds_all = model(one_batch[\"source\"], one_batch[\"source_lengths\"])\n",
        "\n",
        "    for i in range(preds_all.shape[0]):\n",
        "        print(f\"Source: {decode(de_index_to_vocab, one_batch['source'][i].tolist())}\")\n",
        "        print(f\"Pred: {decode(en_index_to_vocab, preds_all[i].tolist())}\")\n",
        "        print(f\"Target: {decode(en_index_to_vocab, targets[i].tolist())}\")\n",
        "        print(\"-\"*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "id": "f55f6162",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source: ein mann mit einem orangefarbenen hut , der etwas <unk> .\n",
            "Pred: a man with a beard in his hat is working on a roof . .\n",
            "Target: a man in an orange hat starring at something .\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Source: ein boston terrier läuft über <unk> - grünes gras vor einem weißen zaun .\n",
            "Pred: a brown dog is running through a field with a white dog that is coming out of the water .\n",
            "Target: a boston terrier is running on lush green grass in front of a white fence .\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Source: ein mädchen in einem karateanzug bricht ein brett mit einem tritt .\n",
            "Pred: a girl in a pink outfit is riding a bicycle in a field .\n",
            "Target: a girl in karate uniform breaking a stick with a front kick .\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Source: fünf leute in winterjacken und mit helmen stehen im schnee mit <unk> im hintergrund .\n",
            "Pred: five people in orange and yellow uniforms are walking through a field with trees in the background .\n",
            "Target: five people wearing winter jackets and helmets stand in the snow , with <unk> in the background .\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Source: leute reparieren das dach eines hauses .\n",
            "Pred: people are walking through a park .\n",
            "Target: people are fixing the roof of a house .\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "translate(basic_model, test_loader, criterion, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
