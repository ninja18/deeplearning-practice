{"train_losses": [4.52667918079225, 3.2836963699777746, 2.6967661706361477, 2.327712293763518, 2.0860480894601294, 1.9321471415952438, 1.8085159420441952, 1.7440745205606132, 1.6752076317035154, 1.6140236093084193, 1.5680290471089569, 1.5776706450836249, 1.5449871171413538, 1.5277342029605143, 1.4895587781452397, 1.4953583400154955, 1.476314161317464, 1.4438341131294352], "val_losses": [3.393812417984009, 2.6239145696163177, 2.182977631688118, 1.9263056963682175, 1.786676898598671, 1.7085549533367157, 1.6566907167434692, 1.6224700063467026, 1.607285887002945, 1.6063076108694077, 1.5993422716856003, 1.6288220286369324, 1.6194685399532318, 1.6588690429925919, 1.661316603422165, 1.6948742121458054, 1.7141211479902267, 1.7200746089220047], "val_bleu_scores": [0.0892399474978447, 0.1766047328710556, 0.25954756140708923, 0.3041071891784668, 0.33653852343559265, 0.35216453671455383, 0.3652110695838928, 0.3695976138114929, 0.3825553357601166, 0.38232913613319397, 0.3816317021846771, 0.37022146582603455, 0.37629052996635437, 0.37120118737220764, 0.3757155239582062, 0.3660586178302765, 0.3680900037288666, 0.36581918597221375], "teacher_forcing_ratios": [0.87, 0.85, 0.83, 0.81, 0.79, 0.76, 0.73, 0.7, 0.67, 0.63, 0.6, 0.56, 0.52, 0.49, 0.45, 0.41, 0.38, 0.34], "batch_size": 128, "learning_rate": 0.0005, "epochs": 40, "model": "AttentionSeq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(5422, 512, padding_idx=0)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (lstm): LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n    (hidden_projection): Linear(in_features=1024, out_features=512, bias=True)\n    (cell_projection): Linear(in_features=1024, out_features=512, bias=True)\n  )\n  (decoder): LuongAttentionDecoder(\n    (embedding): Embedding(4560, 512, padding_idx=0)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (attention): ScaledDotProductAttention()\n    (lstm): LSTM(512, 1024, num_layers=2, batch_first=True, dropout=0.3)\n    (attention_projection): Linear(in_features=2048, out_features=1024, bias=True)\n    (output_projection): Linear(in_features=1024, out_features=4560, bias=True)\n  )\n)", "model_path": "/content/drive/My Drive/ML/Attentions/luong attention/weights/luong-scaled-dot-attention-model.pt", "max_grad_norm": 1.0}